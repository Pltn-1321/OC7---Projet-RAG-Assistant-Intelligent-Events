# Livrables du Projet RAG Events Assistant

> **Documentation compl√®te pour la soumission acad√©mique du projet RAG Events Assistant**

---

## üìã Vue d'Ensemble du Projet

**RAG Events Assistant** est un syst√®me de **Retrieval-Augmented Generation (RAG)** qui combine la recherche s√©mantique et l'intelligence artificielle pour aider les utilisateurs √† d√©couvrir des √©v√©nements culturels via des questions en langage naturel en fran√ßais.

### Qu'est-ce que le RAG ?

Le RAG (Retrieval-Augmented Generation) combine :
- **Retrieval** : Recherche s√©mantique dans une base de connaissances (FAISS)
- **Augmented** : Enrichissement du contexte avec les documents pertinents
- **Generation** : Production de r√©ponses naturelles par un LLM (Mistral AI)

```
Question utilisateur ‚Üí Classification ‚Üí RAG ou Chat ‚Üí R√©ponse + Sources
```

---

## üéØ Contenu des Livrables

Ce dossier contient tous les √©l√©ments requis pour l'√©valuation du projet :

### üìÑ Documentation Principale

| Fichier | Description | Lignes |
|---------|-------------|--------|
| **[01-RAPPORT-TECHNIQUE.md](01-RAPPORT-TECHNIQUE.md)** | Rapport technique complet : architecture, choix technologiques, mod√®les, r√©sultats, am√©liorations | ~1000 |
| **[02-GUIDE-UTILISATION.md](02-GUIDE-UTILISATION.md)** | Guide d'installation et d'utilisation pratique du syst√®me | ~500 |
| **[03-DOCUMENTATION-API.md](03-DOCUMENTATION-API.md)** | R√©f√©rence compl√®te de l'API REST FastAPI | ~460 |
| **[04-RESULTATS-EVALUATION.md](04-RESULTATS-EVALUATION.md)** | Analyse d√©taill√©e des performances et r√©sultats d'√©valuation | ~500 |
| **[05-TESTS-ET-QUALITE.md](05-TESTS-ET-QUALITE.md)** | Strat√©gie de tests, couverture, et qualit√© du code | ~600 |

### üìÇ Annexes

| Fichier | Description |
|---------|-------------|
| **[annexes/architecture-complete.md](annexes/architecture-complete.md)** | Architecture syst√®me d√©taill√©e |
| **[annexes/choix-technologiques.md](annexes/choix-technologiques.md)** | Justifications approfondies des choix technologiques |
| **[annexes/ameliorations-futures.md](annexes/ameliorations-futures.md)** | Roadmap d√©taill√©e et pistes d'am√©lioration |
| **[annexes/schemas/](annexes/schemas/)** | Diagrammes ASCII (pipeline RAG, architecture globale) |

### üìä Donn√©es d'√âvaluation

| Fichier | Description |
|---------|-------------|
| **[donnees-evaluation/test-questions-annote.json](donnees-evaluation/test-questions-annote.json)** | Dataset de 12 questions annot√©es avec mots-cl√©s attendus et cat√©gories |
| **[donnees-evaluation/evaluation-results.json](donnees-evaluation/evaluation-results.json)** | R√©sultats d'√©valuation d√©taill√©s (latence, couverture, classification) |
| **[donnees-evaluation/test-coverage-report.txt](donnees-evaluation/test-coverage-report.txt)** | Rapport de couverture des tests (pytest --cov) |
| **[donnees-evaluation/exemples-reponses.md](donnees-evaluation/exemples-reponses.md)** | Exemples concrets de questions/r√©ponses du syst√®me |

---

## üèÜ M√©triques Cl√©s du Projet

### Performance

| M√©trique | Valeur | Cible | Statut |
|----------|--------|-------|--------|
| **Latence moyenne** | 2.41s | <3.0s | ‚úÖ PASS |
| **Couverture mots-cl√©s** | 81.5% | >80% | ‚úÖ PASS |
| **Classification accuracy** | 100% | ~95% | ‚úÖ EXCELLENT |
| **Test coverage** | 85% | >80% | ‚úÖ PASS |

### Fonctionnalit√©s

- ‚úÖ **Syst√®me RAG fonctionnel** : Classification intelligente SEARCH vs CHAT, recherche s√©mantique FAISS, g√©n√©ration LLM
- ‚úÖ **API REST compl√®te** : 6 endpoints FastAPI avec sessions, background tasks, documentation Swagger
- ‚úÖ **Interface utilisateur** : Streamlit avec chat, historique, sources, th√®me sombre
- ‚úÖ **Tests complets** : Unitaires, int√©gration, end-to-end (pytest + couverture 85%)
- ‚úÖ **√âvaluation RAGAS** : Framework d'√©valuation RAG avec m√©triques de qualit√©
- ‚úÖ **Docker** : Multi-stage build avec support Streamlit et FastAPI
- ‚úÖ **Documentation** : Compl√®te et professionnelle

---

## üõ†Ô∏è Technologies Principales

| Composant | Technologie | Version | R√¥le |
|-----------|-------------|---------|------|
| **LLM** | Mistral AI | mistral-small-latest | G√©n√©ration de r√©ponses conversationnelles |
| **Embeddings** | Mistral Embed | 1024d | Vectorisation s√©mantique multilingue (fran√ßais) |
| **Vector Store** | FAISS | IndexFlatL2 | Recherche de similarit√© ultra-rapide |
| **API** | FastAPI | 0.109+ | REST API avec sessions et background tasks |
| **UI** | Streamlit | 1.52+ | Interface chat moderne et r√©active |
| **Data Source** | Open Agenda API | - | √âv√©nements culturels fran√ßais |
| **Tests** | pytest + RAGAS | 7.4+ | Tests unitaires/int√©gration + √©valuation RAG |
| **Package Manager** | uv | latest | Gestionnaire de d√©pendances moderne (10-100x plus rapide que pip) |

---

## üìö Comment Naviguer les Livrables

### Pour une √âvaluation Compl√®te

1. **Commencez par le rapport technique** : [01-RAPPORT-TECHNIQUE.md](01-RAPPORT-TECHNIQUE.md)
   - Vue d'ensemble compl√®te de l'architecture, des choix, et des r√©sultats
   - Comprendre les d√©cisions techniques et leurs justifications

2. **Testez le syst√®me** : [02-GUIDE-UTILISATION.md](02-GUIDE-UTILISATION.md)
   - Instructions d'installation pas √† pas
   - Exemples d'utilisation concrets
   - Commandes pour lancer l'application

3. **Explorez l'API** : [03-DOCUMENTATION-API.md](03-DOCUMENTATION-API.md)
   - R√©f√©rence compl√®te des endpoints
   - Exemples de requ√™tes curl
   - Mod√®les de donn√©es

4. **Analysez les performances** : [04-RESULTATS-EVALUATION.md](04-RESULTATS-EVALUATION.md)
   - M√©triques d√©taill√©es
   - R√©sultats par cat√©gorie de questions
   - Analyses et recommandations

5. **V√©rifiez la qualit√©** : [05-TESTS-ET-QUALITE.md](05-TESTS-ET-QUALITE.md)
   - Strat√©gie de tests
   - Couverture du code
   - Outils de qualit√© (Black, Ruff, mypy)

6. **Approfondissez** : Consultez les [annexes/](annexes/) pour des d√©tails techniques suppl√©mentaires

### Pour une √âvaluation Rapide (15-30 minutes)

1. **Ce README** : Vue d'ensemble et m√©triques cl√©s (5 min)
2. **[01-RAPPORT-TECHNIQUE.md](01-RAPPORT-TECHNIQUE.md)** : Sections I, II, V, VII (15 min)
3. **[04-RESULTATS-EVALUATION.md](04-RESULTATS-EVALUATION.md)** : R√©sultats globaux et exemples (10 min)
4. **[donnees-evaluation/exemples-reponses.md](donnees-evaluation/exemples-reponses.md)** : Exemples concrets du syst√®me (5 min)

---

## üîó Acc√®s au Code Source

Le code source complet du projet est disponible dans le repository :

```
../../                          (Racine du projet)
‚îú‚îÄ‚îÄ app.py                      (Interface Streamlit)
‚îú‚îÄ‚îÄ src/                        (Code source principal)
‚îÇ   ‚îú‚îÄ‚îÄ api/main.py            (API FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ rag/engine.py          (Moteur RAG)
‚îÇ   ‚îú‚îÄ‚îÄ rag/index_builder.py   (Construction d'index FAISS)
‚îÇ   ‚îú‚îÄ‚îÄ config/                (Configuration et constantes)
‚îÇ   ‚îî‚îÄ‚îÄ data/models.py         (Mod√®les Pydantic)
‚îú‚îÄ‚îÄ tests/                      (Tests unitaires/int√©gration/e2e)
‚îú‚îÄ‚îÄ notebooks/                  (Pipeline de donn√©es Jupyter)
‚îú‚îÄ‚îÄ scripts/                    (Scripts d'√©valuation)
‚îú‚îÄ‚îÄ data/                       (Donn√©es et index FAISS)
‚îú‚îÄ‚îÄ requirements.txt            (D√©pendances pip - cr√©√© pour ce livrable)
‚îî‚îÄ‚îÄ pyproject.toml             (Configuration uv)
```

---

## üì¶ Installation Rapide

### Pr√©requis

- Python 3.11+
- Cl√© API Mistral AI (gratuite sur [console.mistral.ai](https://console.mistral.ai/))

### Option 1 : Avec uv (Recommand√©)

```bash
# Installer uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Installer les d√©pendances
uv sync --all-extras

# Configurer .env
cp .env.example .env
# √âditer .env et ajouter MISTRAL_API_KEY

# Lancer Streamlit
uv run streamlit run app.py

# OU lancer FastAPI
uv run uvicorn src.api.main:app --reload
```

### Option 2 : Avec pip (Compatible)

```bash
# Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Installer d√©pendances
pip install -r requirements.txt

# Configurer .env
cp .env.example .env
# √âditer .env et ajouter MISTRAL_API_KEY

# Lancer l'application
streamlit run app.py
```

### Option 3 : Avec Docker

```bash
# Lancer API + Streamlit
docker-compose up

# Acc√®s:
# - Streamlit: http://localhost:8501
# - API: http://localhost:8000
# - API Docs: http://localhost:8000/docs
```

---

## üß™ Lancer les Tests

```bash
# Tous les tests
uv run pytest

# Avec couverture
uv run pytest --cov=src --cov-report=html
# Ouvrir htmlcov/index.html

# Tests sp√©cifiques
uv run pytest tests/unit/              # Tests unitaires
uv run pytest tests/integration/       # Tests d'int√©gration
uv run pytest tests/e2e/               # Tests end-to-end

# √âvaluation RAG
uv run python scripts/evaluate_rag.py --test-file tests/data/test_questions.json
```

---

## üéì Points Forts du Projet

### Architecture

- ‚úÖ **Classification intelligente** : D√©tection automatique SEARCH vs CHAT (100% accuracy)
- ‚úÖ **Pipeline RAG complet** : Embedding ‚Üí FAISS ‚Üí LLM avec sources v√©rifiables
- ‚úÖ **Direct SDK integration** : Mistral AI et FAISS sans abstraction inutile
- ‚úÖ **Session management** : M√©moire conversationnelle (max 5 √©changes)
- ‚úÖ **Streaming responses** : UX fluide avec r√©ponses progressives

### Qualit√©

- ‚úÖ **85% test coverage** : Tests unitaires, int√©gration, e2e
- ‚úÖ **Code format√©** : Black (line-length 100)
- ‚úÖ **Lint√©** : Ruff (0 erreurs)
- ‚úÖ **Type hints** : mypy (90% des fonctions typ√©es)
- ‚úÖ **Documentation** : Compl√®te et professionnelle

### Performance

- ‚úÖ **Latence < 3s** : Moyenne de 2.41s pour les requ√™tes RAG
- ‚úÖ **Relevance > 80%** : 81.5% de couverture des mots-cl√©s attendus
- ‚úÖ **FAISS ultra-rapide** : IndexFlatL2 avec 497 documents
- ‚úÖ **Batch processing** : Embeddings par batch de 32

### Production-Ready

- ‚úÖ **Docker** : Multi-stage build optimis√©
- ‚úÖ **API REST** : FastAPI avec OpenAPI/Swagger
- ‚úÖ **Configuration** : Pydantic Settings avec validation
- ‚úÖ **Error handling** : Validation Pydantic sur tous les endpoints
- ‚úÖ **Background tasks** : Rebuild d'index non-bloquant

---

## üìû Support et Questions

Pour toute question sur les livrables ou le projet :

- **Documentation compl√®te** : Voir les fichiers dans ce dossier
- **Code source** : Voir le repository complet
- **Issues GitHub** : [Cr√©er une issue](../../issues) (si repository GitHub)

---

## üìÑ License

Ce projet est sous licence MIT. Voir [LICENSE](../../LICENSE) pour plus de d√©tails.

---

<div align="center">

**Fait avec ‚ù§Ô∏è et ‚òï en France**

üé≠ **RAG Events Assistant** - D√©couvrez des √©v√©nements culturels avec l'IA

</div>

---

## üìå Checklist d'√âvaluation

Pour faciliter l'√©valuation, voici une checklist des √©l√©ments √† v√©rifier :

### Documentation (6/6)
- [x] Rapport technique complet (01-RAPPORT-TECHNIQUE.md)
- [x] Guide d'utilisation pratique (02-GUIDE-UTILISATION.md)
- [x] Documentation API REST (03-DOCUMENTATION-API.md)
- [x] R√©sultats d'√©valuation (04-RESULTATS-EVALUATION.md)
- [x] Tests et qualit√© (05-TESTS-ET-QUALITE.md)
- [x] Annexes et sch√©mas (annexes/)

### Fonctionnalit√© (4/4)
- [x] Syst√®me RAG fonctionnel (classification, recherche, g√©n√©ration)
- [x] API REST FastAPI (6 endpoints, sessions, background tasks)
- [x] Interface Streamlit (chat, historique, sources)
- [x] Docker containerization (multi-stage, dual-mode)

### Tests (4/4)
- [x] Tests unitaires (test_models.py, test_rag_engine.py)
- [x] Tests d'int√©gration (test_api.py)
- [x] Tests end-to-end (test_rag_pipeline.py)
- [x] Dataset annot√© (12 questions avec expected keywords)

### Performance (4/4)
- [x] Latence < 3s (2.41s moyenne)
- [x] Couverture > 80% (81.5%)
- [x] Classification 100% accuracy
- [x] Test coverage > 80% (85%)

### Qualit√© Code (4/4)
- [x] Code format√© (Black)
- [x] Lint√© (Ruff, 0 erreurs)
- [x] Type hints (mypy, 90%)
- [x] Documentation inline et externe

**Total : 22/22 ‚úÖ COMPLET**
