{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“¥ RÃ©cupÃ©ration des DonnÃ©es - API OpenAgenda\n",
    "\n",
    "RÃ©cupÃ©ration, validation et export des Ã©vÃ©nements depuis l'API OpenDataSoft.\n",
    "\n",
    "**Ã‰tapes :**\n",
    "\n",
    "1. Configuration et imports\n",
    "2. RÃ©cupÃ©ration des Ã©vÃ©nements (API)\n",
    "3. Validation des donnÃ©es (Pydantic)\n",
    "4. Exploration rapide\n",
    "5. Export (raw + processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ajouter le dossier racine au path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.config.settings import settings\n",
    "from src.config.constants import (\n",
    "    RAW_DATA_DIR,\n",
    "    PROCESSED_DATA_DIR,\n",
    "    RAW_EVENTS_FILE,\n",
    "    PROCESSED_EVENTS_FILE,\n",
    ")\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… Configuration OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Objectif : 10000 Ã©vÃ©nements Ã  Marseille\n"
     ]
    }
   ],
   "source": [
    "# ParamÃ¨tres API\n",
    "API_BASE_URL = \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/evenements-publics-openagenda/records\"\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "MAX_EVENTS = settings.max_events\n",
    "LOCATION = \"Marseille\"  # Ville ciblÃ©e\n",
    "\n",
    "print(f\"ğŸ¯ Objectif : {MAX_EVENTS} Ã©vÃ©nements Ã  {LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ RÃ©cupÃ©ration des DonnÃ©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_openagenda_events(\n",
    "    max_events: int = 100,\n",
    "    location: str = None,\n",
    "    timeout: int = 10,\n",
    "    max_retries: int = 3,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    RÃ©cupÃ¨re les Ã©vÃ©nements depuis l'API OpenDataSoft.\n",
    "\n",
    "    PÃ©riode couverte : Ã©vÃ©nements terminÃ©s dans l'annÃ©e passÃ©e + en cours + futurs.\n",
    "    \"\"\"\n",
    "\n",
    "    all_events = []\n",
    "\n",
    "    # Date de dÃ©part : il y a 1 an (inclut historique rÃ©cent)\n",
    "    date_past = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    params = {\n",
    "        \"limit\": 100,\n",
    "        \"offset\": 0,\n",
    "        \"order_by\": \"firstdate_begin asc\",\n",
    "    }\n",
    "\n",
    "    # Construction du filtre WHERE\n",
    "    where_clauses = []\n",
    "\n",
    "    # Ã‰vÃ©nements non terminÃ©s avant il y a 1 an\n",
    "    where_clauses.append(f'lastdate_end >= \"{date_past}\"')\n",
    "\n",
    "    # Filtre ville optionnel\n",
    "    if location:\n",
    "        where_clauses.append(f'location_city=\"{location}\"')\n",
    "\n",
    "    params[\"where\"] = \" AND \".join(where_clauses)\n",
    "\n",
    "    print(f\"ğŸ“ Filtre : {params['where']}\")\n",
    "\n",
    "    with tqdm(total=max_events, unit=\"evt\", desc=\"ğŸ“¥ RÃ©cupÃ©ration\") as pbar:\n",
    "        while len(all_events) < max_events:\n",
    "            params[\"limit\"] = min(100, max_events - len(all_events))\n",
    "\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = requests.get(\n",
    "                        API_BASE_URL, params=params, headers=headers, timeout=timeout\n",
    "                    )\n",
    "                    response.raise_for_status()\n",
    "\n",
    "                    data = response.json()\n",
    "                    records = data.get(\"results\", [])\n",
    "\n",
    "                    # Log premiÃ¨re requÃªte\n",
    "                    if params[\"offset\"] == 0:\n",
    "                        total = data.get(\"total_count\", 0)\n",
    "                        print(f\"ğŸ“Š Total disponible : {total}\")\n",
    "\n",
    "                    if not records:\n",
    "                        logger.info(f\"âœ… {len(all_events)} Ã©vÃ©nements rÃ©cupÃ©rÃ©s\")\n",
    "                        return all_events\n",
    "\n",
    "                    all_events.extend(records)\n",
    "                    pbar.update(len(records))\n",
    "                    params[\"offset\"] += len(records)\n",
    "\n",
    "                    if len(records) < params[\"limit\"]:\n",
    "                        logger.info(f\"âœ… {len(all_events)} Ã©vÃ©nements rÃ©cupÃ©rÃ©s\")\n",
    "                        return all_events\n",
    "\n",
    "                    break\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        logger.error(f\"âŒ Ã‰chec aprÃ¨s {max_retries} tentatives: {e}\")\n",
    "                        return all_events\n",
    "                    time.sleep(2**attempt)\n",
    "\n",
    "    return all_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Filtre : lastdate_end >= \"2025-01-16\" AND location_city=\"Marseille\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eda2bafd2b44aca86fdd9772160f74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ“¥ RÃ©cupÃ©ration:   0%|          | 0/10000 [00:00<?, ?evt/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Total disponible : 497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: âœ… 497 Ã©vÃ©nements rÃ©cupÃ©rÃ©s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… 497 Ã©vÃ©nements rÃ©cupÃ©rÃ©s en 5.9s\n",
      "âš¡ Vitesse : 84.8 evts/sec\n"
     ]
    }
   ],
   "source": [
    "# RÃ©cupÃ©ration\n",
    "start_time = datetime.now()\n",
    "\n",
    "raw_events = fetch_openagenda_events(\n",
    "    max_events=MAX_EVENTS,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "duration = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\nâœ… {len(raw_events)} Ã©vÃ©nements rÃ©cupÃ©rÃ©s en {duration:.1f}s\")\n",
    "print(f\"âš¡ Vitesse : {len(raw_events) / duration:.1f} evts/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Validation Pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/qkptv90j2yj8jtfdqg5c16_00000gn/T/ipykernel_22782/1851160795.py:6: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  class Event(BaseModel):\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Event(BaseModel):\n",
    "    \"\"\"ModÃ¨le Pydantic pour validation des Ã©vÃ©nements.\"\"\"\n",
    "\n",
    "    uid: str\n",
    "    title: str = Field(alias=\"title_fr\")\n",
    "    description: Optional[str] = Field(default=None, alias=\"description_fr\")\n",
    "    start_date: str = Field(alias=\"firstdate_begin\")\n",
    "    end_date: str = Field(alias=\"lastdate_end\")  # â† UTILISER lastdate_end\n",
    "    city: Optional[str] = Field(default=None, alias=\"location_city\")\n",
    "    address: Optional[str] = Field(default=None, alias=\"location_address\")\n",
    "    url: Optional[str] = Field(default=None, alias=\"canonicalurl\")\n",
    "\n",
    "    @field_validator(\"end_date\")\n",
    "    @classmethod\n",
    "    def validate_end_date(cls, v):\n",
    "        \"\"\"Valide que l'Ã©vÃ©nement n'est pas trop ancien.\"\"\"\n",
    "        date_limit = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Extraire seulement la date (YYYY-MM-DD) si ISO format complet\n",
    "        event_date = v[:10] if len(v) > 10 else v\n",
    "\n",
    "        if event_date < date_limit:\n",
    "            raise ValueError(f\"Ã‰vÃ©nement trop ancien (terminÃ© le {event_date})\")\n",
    "\n",
    "        return v\n",
    "\n",
    "    class Config:\n",
    "        populate_by_name = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660b4809ccc142ddbb475bcec64140a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "âœ… Validation:   0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ValidÃ©s : 497\n",
      "ğŸ” FiltrÃ©s (trop anciens) : 0\n",
      "âŒ Erreurs : 0\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "validated_events = []\n",
    "filtered_count = 0\n",
    "errors = []\n",
    "\n",
    "for event_data in tqdm(raw_events, desc=\"âœ… Validation\"):\n",
    "    try:\n",
    "        event = Event(**event_data)\n",
    "        validated_events.append(event)\n",
    "    except ValueError as e:\n",
    "        # Ã‰vÃ©nement filtrÃ© car trop ancien\n",
    "        if \"trop ancien\" in str(e):\n",
    "            filtered_count += 1\n",
    "        else:\n",
    "            errors.append({\"uid\": event_data.get(\"uid\"), \"error\": str(e)})\n",
    "    except Exception as e:\n",
    "        errors.append({\"uid\": event_data.get(\"uid\"), \"error\": str(e)})\n",
    "\n",
    "print(f\"\\nâœ… ValidÃ©s : {len(validated_events)}\")\n",
    "print(f\"ğŸ” FiltrÃ©s (trop anciens) : {filtered_count}\")\n",
    "print(f\"âŒ Erreurs : {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Conversion en DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame([event\u001b[38;5;241m.\u001b[39mmodel_dump() \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m validated_events])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“Š AperÃ§u des donnÃ©es :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Conversion en DataFrame\n",
    "df = pd.DataFrame([event.model_dump() for event in validated_events])\n",
    "\n",
    "print(\"ğŸ“Š AperÃ§u des donnÃ©es :\")\n",
    "print(df[[\"title\", \"city\", \"start_date\"]].head())\n",
    "\n",
    "print(f\"\\nğŸ“ Shape : {df.shape}\")\n",
    "print(f\"\\nğŸ“‹ Colonnes : {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Distribution par ville :\n",
      "city\n",
      "Marseille    497\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ“… PÃ©riode couverte :\n",
      "  Du 2022-06-14T07:00:00+00:00 au 2032-01-01T01:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Statistiques rapides\n",
    "print(\"ğŸ“ˆ Distribution par ville :\")\n",
    "print(df[\"city\"].value_counts().head(10))\n",
    "\n",
    "print(\"\\nğŸ“… PÃ©riode couverte :\")\n",
    "print(f\"  Du {df['start_date'].min()} au {df['start_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ DonnÃ©es brutes : /Users/ppluton/Documents/Repositories/OC7---Projet-RAG-Assistant-Intelligent-Events/data/raw/events_raw.json\n",
      "ğŸ’¾ DonnÃ©es traitÃ©es : /Users/ppluton/Documents/Repositories/OC7---Projet-RAG-Assistant-Intelligent-Events/data/processed/events_processed.json\n",
      "\n",
      "âœ… Export terminÃ© !\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©er les dossiers si nÃ©cessaire\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export donnÃ©es brutes (tel quel depuis l'API)\n",
    "raw_path = RAW_DATA_DIR / RAW_EVENTS_FILE\n",
    "with open(raw_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(raw_events, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ’¾ DonnÃ©es brutes : {raw_path}\")\n",
    "\n",
    "# Export donnÃ©es traitÃ©es (validÃ©es Pydantic)\n",
    "processed_path = PROCESSED_DATA_DIR / PROCESSED_EVENTS_FILE\n",
    "processed_dict = [event.model_dump(mode=\"json\") for event in validated_events]\n",
    "with open(processed_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(processed_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ’¾ DonnÃ©es traitÃ©es : {processed_path}\")\n",
    "\n",
    "print(\"\\nâœ… Export terminÃ© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… RÃ©sumÃ©\n",
    "\n",
    "- âœ… RÃ©cupÃ©ration API OK\n",
    "- âœ… Validation Pydantic OK\n",
    "- âœ… Export raw + processed OK\n",
    "\n",
    "**Prochaine Ã©tape** : PrÃ©paration des donnÃ©es pour le RAG (notebook 02)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC7---Projet-RAG-Assistant-Intelligent-Events",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
