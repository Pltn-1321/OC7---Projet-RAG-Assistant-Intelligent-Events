# Rapport Technique - RAG Events Assistant

> **SystÃ¨me RAG (Retrieval-Augmented Generation) pour la dÃ©couverte d'Ã©vÃ©nements culturels**

**Auteur** : Pierre Pluton
**Date** : FÃ©vrier 2026
**Version** : 2.0 (Monorepo avec React + PostgreSQL)
**Projet** : OpenClassrooms - Projet RAG Assistant Intelligent

---

## Table des MatiÃ¨res

- [I. INTRODUCTION](#i-introduction)
- [II. ARCHITECTURE DU SYSTÃˆME](#ii-architecture-du-systÃ¨me)
- [III. CHOIX TECHNOLOGIQUES](#iii-choix-technologiques)
- [IV. MODÃˆLES UTILISÃ‰S](#iv-modÃ¨les-utilisÃ©s)
- [V. RÃ‰SULTATS OBSERVÃ‰S](#v-rÃ©sultats-observÃ©s)
- [VI. PISTES D'AMÃ‰LIORATION](#vi-pistes-damÃ©lioration)
- [VII. CONCLUSION](#vii-conclusion)

---

## I. INTRODUCTION

### 1.1 Contexte du Projet

La dÃ©couverte d'Ã©vÃ©nements culturels reprÃ©sente un dÃ©fi pour les utilisateurs :
- **Fragmentation des sources** : Multiples plateformes, agendas, sites web
- **Recherche traditionnelle limitÃ©e** : RequÃªtes par mots-clÃ©s exactes, pas de comprÃ©hension sÃ©mantique
- **Absence de personnalisation** : DifficultÃ© Ã  trouver des Ã©vÃ©nements correspondant Ã  des critÃ¨res flous ("quelque chose de sympa ce weekend")

**Solution proposÃ©e** : Un systÃ¨me RAG (Retrieval-Augmented Generation) qui combine :
- Recherche sÃ©mantique dans une base d'Ã©vÃ©nements (FAISS)
- GÃ©nÃ©ration de rÃ©ponses conversationnelles (Mistral AI)
- Interfaces multiples (Frontend React + Streamlit + API REST)
- Persistence des sessions utilisateurs (PostgreSQL)

### 1.2 Qu'est-ce que le RAG ?

**RAG (Retrieval-Augmented Generation)** est une architecture d'IA qui enrichit les rÃ©ponses des LLM avec des informations rÃ©cupÃ©rÃ©es depuis une base de connaissances externe.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PIPELINE RAG                                â”‚
â”‚                                                                  â”‚
â”‚  Question utilisateur                                            â”‚
â”‚       â†“                                                          â”‚
â”‚  Classification intelligente (needs_rag)                         â”‚
â”‚       â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   CHAT Mode        â”‚   SEARCH Mode      â”‚                    â”‚
â”‚  â”‚   (Simple LLM)     â”‚   (RAG Pipeline)   â”‚                    â”‚
â”‚  â”‚   â†“                â”‚   â†“                â”‚                    â”‚
â”‚  â”‚   Conversation     â”‚   1. Embedding     â”‚                    â”‚
â”‚  â”‚   directe          â”‚   2. FAISS Search  â”‚                    â”‚
â”‚  â”‚                    â”‚   3. LLM + Context â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚       â†“                                                          â”‚
â”‚  RÃ©ponse contextuelle + Sources                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Pourquoi le RAG plutÃ´t que le Fine-tuning ?

| Aspect | RAG | Fine-tuning |
|--------|-----|-------------|
| **Mise Ã  jour donnÃ©es** | InstantanÃ©e (rÃ©-indexation) | Re-training requis |
| **CoÃ»t** | Faible (API embeddings) | Ã‰levÃ© (GPU, compute) |
| **TraÃ§abilitÃ©** | Sources citables | BoÃ®te noire |
| **Hallucinations** | RÃ©duites (contexte factuel) | Plus frÃ©quentes |
| **Connaissances** | LimitÃ©es Ã  la base | IntÃ©grÃ©es au modÃ¨le |

**Cas d'usage typiques du RAG** :
- Questions-rÃ©ponses sur documents internes
- Assistants basÃ©s sur donnÃ©es actualisÃ©es
- Chatbots avec sources vÃ©rifiables
- Recherche sÃ©mantique augmentÃ©e

### 1.3 Objectifs et PÃ©rimÃ¨tre

**Objectifs fonctionnels** :
- âœ… Permettre la recherche d'Ã©vÃ©nements en langage naturel (franÃ§ais)
- âœ… Fournir des recommandations pertinentes avec sources vÃ©rifiables
- âœ… GÃ©rer des conversations multi-tours avec mÃ©moire de session
- âœ… Distinguer questions conversationnelles vs recherches d'Ã©vÃ©nements

**Objectifs techniques** :
- âœ… Latence < 3 secondes pour les requÃªtes RAG
- âœ… Couverture des mots-clÃ©s > 80%
- âœ… Classification SEARCH vs CHAT > 95% accuracy
- âœ… Test coverage > 80%

**PÃ©rimÃ¨tre** :
- Base d'Ã©vÃ©nements : Open Agenda API (Ã©vÃ©nements culturels franÃ§ais)
- Langue : FranÃ§ais uniquement
- DÃ©ploiement : Local/Docker (pas de cloud dans ce POC)

### 1.4 Livrables

1. **SystÃ¨me RAG fonctionnel** : Code source complet avec RAGEngine, IndexBuilder
2. **API REST** : FastAPI avec 6 endpoints, sessions PostgreSQL, background tasks
3. **Interfaces utilisateur** :
   - Frontend React (5 vues : Chat, API Explorer, Monitoring, RAGAS, Index)
   - Streamlit (alternative simplifiÃ©e)
4. **Tests** : Unitaires, intÃ©gration, end-to-end (pytest, 85% coverage)
5. **Documentation** : ComplÃ¨te et professionnelle (ce rapport inclus)
6. **Ã‰valuation** : Framework RAGAS, dataset annotÃ©, mÃ©triques
7. **CI/CD** : GitHub Actions (lint, build, docker)

---

## II. ARCHITECTURE DU SYSTÃˆME

### 2.1 Vue d'Ensemble

L'architecture suit un pattern 4 couches :

```
UTILISATEUR
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE PRÃ‰SENTATION                                     â”‚
â”‚  - Frontend React (5173) â† Application principale        â”‚
â”‚  - Streamlit UI (8501)   â† Alternative                   â”‚
â”‚  - FastAPI REST API (8000)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE LOGIQUE MÃ‰TIER                                   â”‚
â”‚  - RAGEngine (classification, search, generation)        â”‚
â”‚  - IndexBuilder (construction FAISS)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE DONNÃ‰ES                                          â”‚
â”‚  - PostgreSQL (sessions, messages, mÃ©tadonnÃ©es)          â”‚
â”‚  - FAISS Index (index.faiss + index.pkl)                â”‚
â”‚  - Documents JSON (rag_documents.json)                   â”‚
â”‚  - Services externes (Mistral API, Open Agenda)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Principe architectural** : SÃ©paration des responsabilitÃ©s (SoC)
- **PrÃ©sentation** : GÃ¨re l'interaction utilisateur (UI/API)
- **Logique mÃ©tier** : ImplÃ©mente le pipeline RAG
- **DonnÃ©es** : Stockage et accÃ¨s aux Ã©vÃ©nements

### 2.2 Composants Principaux

#### 2.2.1 RAGEngine (`src/rag/engine.py`)

Le cÅ“ur du systÃ¨me RAG avec les mÃ©thodes :

**`needs_rag(query: str) -> bool`**
- Classifie si la requÃªte nÃ©cessite une recherche dans la base
- Utilise un prompt LLM pour distinguer SEARCH vs CHAT
- Exemples SEARCH : "concerts jazz Paris", "expositions gratuites"
- Exemples CHAT : "bonjour", "merci", "comment Ã§a va"
- **Accuracy observÃ©e** : 100% (12/12 questions test)

**`encode_query(query: str) -> np.ndarray`**
- GÃ©nÃ¨re l'embedding de la requÃªte
- Support Mistral Embed (1024d) ou SentenceTransformers (768d)
- Normalisation L2 pour compatibilitÃ© distance cosinus
- Batch processing pour efficacitÃ©

**`search(query: str, top_k: int) -> List[Dict]`**
- Recherche sÃ©mantique dans l'index FAISS
- Retourne top-k documents avec scores de similaritÃ©
- Filtrage par seuil de similaritÃ© (dÃ©faut: 0.3)
- MÃ©tadonnÃ©es enrichies (ville, date, prix, URL)

**`generate_response(query: str, context: str) -> str`**
- GÃ©nÃ©ration LLM avec Mistral AI
- Streaming support pour UX fluide
- Prompt template avec instructions spÃ©cifiques (franÃ§ais, 2-3 Ã©vÃ©nements max)
- TempÃ©rature 0.7 pour Ã©quilibre crÃ©ativitÃ©/consistance

**`chat(query: str, history: List, top_k: int) -> Dict`**
- Pipeline complet unifiÃ©
- Appelle needs_rag() puis search() ou conversation directe
- GÃ¨re l'historique de conversation (max 5 Ã©changes)
- Retourne rÃ©ponse + sources (si RAG) + mÃ©tadonnÃ©es

#### 2.2.2 IndexBuilder (`src/rag/index_builder.py`)

Construction et gestion des index FAISS :

**`load_documents() -> List[Event]`**
- Charge Ã©vÃ©nements depuis `rag_documents.json`
- Validation Pydantic pour intÃ©gritÃ© des donnÃ©es
- Conversion en objets Event avec mÃ©tadonnÃ©es

**`generate_embeddings(documents: List[str]) -> np.ndarray`**
- Batch embedding generation (batch_size=32)
- Progress tracking avec tqdm
- Retry logic (3 tentatives avec backoff exponentiel)
- Support Mistral API et modÃ¨les locaux

**`build_index(embeddings: np.ndarray) -> faiss.Index`**
- CrÃ©ation IndexFlatL2 (recherche exacte)
- Normalisation L2 des vecteurs (distance L2 â‰ˆ cosinus)
- Ajout des vecteurs Ã  l'index
- Optimisation pour < 1M documents

**`save_index(index, metadata, config)`**
- Sauvegarde index FAISS (`events.index`)
- Persistance mÃ©tadonnÃ©es avec pickle (`metadata.pkl`)
- Configuration JSON (`config.json`) avec:
  - embedding_dim, num_documents, model_name
  - date de crÃ©ation, provider (mistral/sentence-transformers)

**`rebuild() -> Dict`**
- Pipeline complet de reconstruction
- Callbacks pour progress tracking
- Validation des rÃ©sultats
- Invalidation du cache RAGEngine

#### 2.2.3 API FastAPI (`src/api/main.py`)

API REST complÃ¨te avec 6 endpoints :

**GET `/health`**
- Health check du service
- Retourne : status, num_documents, embedding_dim, active_sessions
- Code 503 si index non disponible

**POST `/search`**
- Recherche sÃ©mantique sans session
- Params : `query` (string), `top_k` (int, dÃ©faut 5)
- Retourne : rÃ©sultats avec scores de similaritÃ©

**POST `/chat`**
- Chat avec mÃ©moire conversationnelle
- Params : `query`, `session_id` (optionnel), `top_k`
- Auto-gÃ©nÃ¨re session_id si non fourni (UUID v4)
- Retourne : response, sources, session_id

**GET `/session/{session_id}`**
- RÃ©cupÃ¨re historique d'une session
- Retourne : liste de messages (user/assistant)
- Code 404 si session non trouvÃ©e

**DELETE `/session/{session_id}`**
- Supprime une session et son historique
- Retourne : confirmation de suppression
- Code 404 si session non trouvÃ©e

**POST `/rebuild`**
- Reconstruit l'index FAISS en arriÃ¨re-plan
- Authentification : Header `X-API-Key`
- Retourne : task_id pour tracking
- Background task avec progress callbacks

**GET `/rebuild/{task_id}`**
- Statut d'une tÃ¢che de reconstruction
- Retourne : status (in_progress/completed/failed), progress (0-1), message
- Code 404 si tÃ¢che non trouvÃ©e

**CaractÃ©ristiques techniques** :
- Validation Pydantic pour toutes les requÃªtes/rÃ©ponses
- Gestion des sessions en PostgreSQL (SQLAlchemy async)
- ModÃ¨les : `SessionModel`, `MessageModel` avec JSONB pour sources
- Historique limitÃ© Ã  5 Ã©changes par session
- Documentation Swagger auto-gÃ©nÃ©rÃ©e (`/docs`)
- CORS configurable pour intÃ©gration frontend React

#### 2.2.4 Interface Streamlit (`app.py`)

Interface chat moderne et rÃ©active :

**FonctionnalitÃ©s** :
- Chat conversationnel avec input utilisateur
- Affichage de l'historique (max 5 messages)
- Visualisation des sources avec scores de similaritÃ©
- Sidebar avec configuration :
  - top_k (nombre de rÃ©sultats)
  - tempÃ©rature LLM (crÃ©ativitÃ©)
  - bouton rÃ©initialisation conversation
- ThÃ¨me sombre moderne
- Streaming des rÃ©ponses (UX fluide)

**Optimisations** :
- `@st.cache_resource` pour RAGEngine (1 instance partagÃ©e)
- `st.session_state` pour mÃ©moire de conversation
- CSS personnalisÃ© pour design professionnel

### 2.3 Flux de DonnÃ©es

#### Pipeline de Chat Complet

```
1. RequÃªte utilisateur
       â”‚
       â–¼
2. Classification (needs_rag?)
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                      â”‚
   [SEARCH]               [CHAT]
       â”‚                      â”‚
       â–¼                      â–¼
3. Encodage requÃªte    4. RÃ©ponse directe
   (mistral-embed)        (sans RAG)
   â†’ embedding 1024d
       â”‚
       â–¼
4. Recherche FAISS
   (IndexFlatL2)
   â†’ distance L2
       â”‚
       â–¼
5. Top-K documents
   (similaritÃ© cosinus)
       â”‚
       â–¼
6. GÃ©nÃ©ration LLM
   avec contexte
   (mistral-small)
       â”‚
       â–¼
7. RÃ©ponse + Sources
```

**Temps de traitement typique** :
- CHAT mode : 1.5-2s (pas de FAISS)
- SEARCH mode : 2-3s (embedding + FAISS + LLM)

#### Pipeline de Reconstruction d'Index

```
1. POST /rebuild
   (avec X-API-Key)
       â”‚
       â–¼
2. Validation API Key
       â”‚
       â–¼
3. TÃ¢che en arriÃ¨re-plan
       â”‚
       â”œâ”€â–¶ Charger documents (rag_documents.json)
       â”‚
       â”œâ”€â–¶ GÃ©nÃ©rer embeddings (batch de 32)
       â”‚   Progress: 0/497 â†’ 32/497 â†’ ... â†’ 497/497
       â”‚
       â”œâ”€â–¶ Construire index FAISS
       â”‚   IndexFlatL2(dimension=1024)
       â”‚   L2 normalization
       â”‚
       â””â”€â–¶ Sauvegarder fichiers
           - events.index (FAISS)
           - metadata.pkl (Ã©vÃ©nements + mÃ©tadonnÃ©es)
           - config.json (configuration)

4. Invalidation cache RAGEngine
       â”‚
       â–¼
5. Nouvel index disponible
```

**DurÃ©e typique** : 30-60 secondes pour 497 Ã©vÃ©nements (Mistral Embed)

### 2.4 Structure des Modules

Le projet utilise une **architecture monorepo** avec sÃ©paration backend/frontend :

```
OC7---Projet-RAG-Assistant-Intelligent-Events/
â”œâ”€â”€ backend/                    # API Python + RAG Engine
â”‚   â”œâ”€â”€ app.py                  # Interface Streamlit
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/             # settings.py, constants.py
â”‚   â”‚   â”œâ”€â”€ data/               # models.py (Pydantic)
â”‚   â”‚   â”œâ”€â”€ database/           # ğŸ†• models.py, repository.py, connection.py
â”‚   â”‚   â”œâ”€â”€ rag/                # engine.py, index_builder.py, embeddings.py
â”‚   â”‚   â””â”€â”€ api/                # main.py (FastAPI)
â”‚   â”œâ”€â”€ tests/                  # unit, integration, e2e
â”‚   â”œâ”€â”€ notebooks/              # Pipeline de donnÃ©es (Jupyter)
â”‚   â””â”€â”€ pyproject.toml          # DÃ©pendances Python (uv)
â”‚
â”œâ”€â”€ frontend/                   # ğŸ†• Application React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ features/           # chat, api-explorer, monitoring, ragas-metrics
â”‚   â”‚   â”œâ”€â”€ components/         # ui (shadcn), layout, common
â”‚   â”‚   â”œâ”€â”€ lib/api/            # client.ts, endpoints.ts, types.ts
â”‚   â”‚   â””â”€â”€ store/              # Zustand stores
â”‚   â”œâ”€â”€ package.json            # DÃ©pendances Node.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ docker-compose.yml          # Orchestration services
â”œâ”€â”€ .github/workflows/          # ğŸ†• CI/CD GitHub Actions
â””â”€â”€ README.md
```

**Avantages du monorepo** :
- SÃ©paration claire backend (Python) / frontend (TypeScript)
- Chaque partie a ses propres dÃ©pendances et Dockerfile
- DÃ©ploiement unifiÃ© via docker-compose
- CI/CD partagÃ©

---

## III. CHOIX TECHNOLOGIQUES

### 3.1 LLM : Mistral AI (`mistral-small-latest`)

#### Justification

**âœ… Avantages** :
- **Support natif du franÃ§ais** : ModÃ¨le entraÃ®nÃ© sur corpus multilingue avec fort biais franÃ§ais
- **QualitÃ© des rÃ©ponses** : Comparable Ã  GPT-3.5, meilleur que Llama 2
- **API simple** : SDK Python officiel, intÃ©gration facile
- **Pricing compÃ©titif** : $0.001/1K tokens (input), $0.003/1K tokens (output)
- **Streaming support** : RÃ©ponses progressives pour UX fluide
- **32K context window** : Suffisant pour 5-10 Ã©vÃ©nements + historique

**âŒ Alternatives non retenues** :
- **GPT-4** : Plus cher ($0.03/1K), US-centric, latence plus Ã©levÃ©e
- **Llama 3** : NÃ©cessite GPU local, dÃ©ploiement complexe, qualitÃ© infÃ©rieure pour franÃ§ais
- **Claude** : Support franÃ§ais limitÃ©, pas de streaming dans SDK

#### Configuration

```python
{
  "model": "mistral-small-latest",  # Auto-update vers derniÃ¨re version
  "temperature": 0.7,               # Ã‰quilibre crÃ©ativitÃ©/consistance
  "max_tokens": 1000,               # ~750 mots max
  "top_p": 1.0,                     # Nucleus sampling
  "stream": True                    # Streaming des rÃ©ponses
}
```

**Prompt systÃ¨me** (extrait de `constants.py`) :
```
Tu es un assistant intelligent qui aide les utilisateurs Ã  dÃ©couvrir 
des Ã©vÃ©nements culturels. RÃ©ponds en franÃ§ais de maniÃ¨re naturelle 
et conversationnelle. Recommande 2-3 Ã©vÃ©nements pertinents maximum 
avec informations pratiques (date, lieu, prix). Si aucun Ã©vÃ©nement 
ne correspond, propose des alternatives. Sois concis mais informatif.
```

### 3.2 Embeddings : Mistral Embed (1024d)

#### Justification

**âœ… Avantages** :
- **Multilingue optimisÃ©** : Excellent sur franÃ§ais (meilleur que OpenAI ada-002)
- **Dimension Ã©levÃ©e** : 1024d vs 1536d (OpenAI) ou 768d (sentence-transformers)
- **MÃªme provider** : CohÃ©rence avec LLM, facturation unifiÃ©e
- **Pas de modÃ¨le local** : Pas de gestion de dÃ©pendances ML lourdes
- **Normalisation incluse** : Vecteurs prÃ©-normalisÃ©s

**âŒ Alternatives non retenues** :
- **OpenAI ada-002** : Plus cher, US-centric, 1536d (surdimensionnÃ©)
- **Voyage AI** : Moins connu, pas de SDK Python mature
- **E5-multilingual** : QualitÃ© infÃ©rieure sur franÃ§ais

#### Fallback : sentence-transformers

Configuration alternative pour dÃ©veloppement local :

```python
{
  "model": "paraphrase-multilingual-mpnet-base-v2",
  "dimension": 768,
  "device": "cpu",  # ou "cuda" si GPU disponible
  "normalize": True
}
```

**UtilisÃ© quand** :
- DÃ©veloppement sans connexion internet
- Tests CI/CD (Ã©vite appels API)
- Budget limitÃ© (free, local)

**Performance** : ~80% de la qualitÃ© Mistral Embed sur franÃ§ais

### 3.3 Vector Store : FAISS

#### Justification

**âœ… Avantages** :
- **Ultra-rapide** : OptimisÃ© C++, recherche en <1ms pour 1K vecteurs
- **Pas de serveur** : Fichiers locaux (.index + .pkl)
- **Flexible** : Multiples types d'index (Flat, IVF, HNSW)
- **Open source** : Facebook Research, mature (depuis 2017)
- **Python bindings** : IntÃ©gration native

**Index actuel** : `IndexFlatL2` (recherche exacte)
- ComplexitÃ© : O(n Ã— d) par requÃªte
- Optimal pour < 100K vecteurs
- 100% recall (pas d'approximation)

**âŒ Alternatives non retenues** :

| Alternative | Avantages | Pourquoi non retenu |
|-------------|-----------|---------------------|
| **Pinecone** | Cloud, scalable | CoÃ»t mensuel, dÃ©pendance externe |
| **Weaviate** | GraphQL, filtres | Overkill pour 500 Ã©vÃ©nements |
| **Qdrant** | Performant, Rust | ComplexitÃ© dÃ©ploiement |
| **Chroma** | Simple, embeddings | Moins performant que FAISS |
| **Milvus** | DistribuÃ© | Pour >1M vecteurs |

**Ã‰volution future** : `IndexIVFFlat` pour >10K Ã©vÃ©nements
- Recherche approximative (95-98% recall)
- 10-100x plus rapide
- Trade-off acceptable pour production

### 3.4 API Framework : FastAPI

#### Justification

**âœ… Avantages** :
- **Async native** : Support asyncio pour haute concurrence
- **Validation automatique** : Pydantic pour requÃªtes/rÃ©ponses
- **Documentation auto** : Swagger UI + ReDoc gratuits
- **Performance** : Comparable Ã  Node.js/Go (Starlette + uvicorn)
- **Type hints** : SÃ©curitÃ© des types au dÃ©veloppement
- **Background tasks** : Support natif pour tÃ¢ches longues

**âŒ Alternative non retenue** :
- **Flask** : Pas d'async natif, validation manuelle, plus lent

**Exemple d'endpoint avec validation** :
```python
@app.post("/search", response_model=SearchResponse)
async def search(request: SearchRequest):
    # Pydantic valide automatiquement:
    # - query: str (min 1, max 500 chars)
    # - top_k: int (1-20)
    ...
```

### 3.5 UI : Streamlit

#### Justification

**âœ… Avantages** :
- **Prototypage rapide** : Chat interface en <200 lignes
- **Python pur** : Pas de JavaScript/HTML/CSS requis
- **Session state** : Gestion mÃ©moire conversationnelle intÃ©grÃ©e
- **Composants riches** : Chat, markdown, code, graphiques
- **RÃ©activitÃ©** : Re-run automatique sur changement

**âŒ Limitations** :
- Pas pour production web (performances limitÃ©es)
- Customisation CSS difficile
- Multi-utilisateurs limitÃ© (pas de vrais WebSockets)

**Pour production** : Frontend React + API FastAPI sÃ©parÃ©e

### 3.6 Package Manager : uv

#### Justification

**âœ… Avantages** :
- **10-100x plus rapide** que pip
- **Lock file** : Builds reproductibles (uv.lock)
- **RÃ©solution moderne** : GÃ¨re les conflits de dÃ©pendances
- **Virtual env intÃ©grÃ©** : Pas besoin de venv manuel
- **Compatible pip** : `uv pip install` marchant comme pip

**Commandes Ã©quivalentes** :
```bash
# pip
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# uv (simplifiÃ©)
uv sync
```

### 3.7 Data Source : Open Agenda API

#### Justification

**âœ… Avantages** :
- **Exhaustif** : Milliers d'Ã©vÃ©nements culturels franÃ§ais
- **Gratuit** : Tier gratuit suffisant (rate limits raisonnables)
- **StructurÃ©** : JSON avec mÃ©tadonnÃ©es riches (date, lieu, prix, catÃ©gories)
- **ActualisÃ©** : Mise Ã  jour quotidienne par organisateurs
- **API REST** : Facile d'intÃ©gration

**Structure Ã©vÃ©nement** :
```json
{
  "uid": "123456",
  "title": "Concert de Jazz",
  "description": "...",
  "location": {
    "city": "Paris",
    "address": "...",
    "latitude": 48.8566,
    "longitude": 2.3522
  },
  "timings": [{
    "begin": "2025-01-20T20:00:00",
    "end": "2025-01-20T23:00:00"
  }],
  "freeText": {
    "fr": "Gratuit"
  },
  "links": ["https://..."]
}
```

### 3.8 Database : PostgreSQL + SQLAlchemy

#### Justification

**âœ… Avantages** :
- **Persistence** : Sessions survivent aux redÃ©marrages du serveur
- **Async Support** : SQLAlchemy 2.0 avec asyncpg pour performances
- **JSONB** : Stockage flexible des mÃ©tadonnÃ©es et sources RAG
- **ScalabilitÃ©** : PrÃªt pour dÃ©ploiement multi-instances
- **Transactions** : Garanties ACID pour intÃ©gritÃ© des donnÃ©es

**âŒ Alternatives non retenues** :
- **Redis** : Plus rapide mais moins structurÃ©, pas de requÃªtes complexes
- **MongoDB** : Overkill pour ce cas d'usage, pas d'async natif mature
- **SQLite** : Pas adaptÃ© pour multi-utilisateurs concurrents

#### ModÃ¨les de DonnÃ©es

```python
class SessionModel(Base):
    id: UUID                    # Primary key
    user_id: Optional[str]      # Pour filtrage par utilisateur
    created_at: datetime        # Avec timezone
    updated_at: datetime
    metadata: dict              # JSONB

class MessageModel(Base):
    id: int                     # Auto-increment
    session_id: UUID            # Foreign key â†’ Session
    role: str                   # 'user' ou 'assistant'
    content: str                # Texte du message
    sources: Optional[dict]     # JSONB avec Ã©vÃ©nements RAG
    latency_ms: Optional[float] # Performance tracking
    query_type: Optional[str]   # 'chat' ou 'search'
```

#### Configuration

```python
{
  "pool_size": 10,           # Connexions persistentes
  "max_overflow": 20,        # Connexions additionnelles
  "pool_pre_ping": True,     # Health check automatique
  "echo": False              # Debug SQL (dÃ©sactivÃ© en prod)
}
```

### 3.9 Frontend : React 18 + TypeScript + Vite

#### Justification

**âœ… Avantages** :
- **Type Safety** : TypeScript pour robustesse et meilleure DX
- **Performance** : Vite pour builds ultra-rapides (<1s HMR)
- **UI Components** : shadcn/ui + Tailwind CSS pour design moderne
- **State Management** : TanStack Query (server) + Zustand (client)
- **Production-ready** : Docker multi-stage build optimisÃ©

**âŒ Pourquoi pas rester sur Streamlit seul ?**
- Streamlit limitÃ© en personnalisation UI
- Pas de vrais WebSockets pour temps rÃ©el
- Performances multi-utilisateurs limitÃ©es
- Difficile Ã  intÃ©grer dans infrastructure existante

#### Stack Frontend

| Technologie | Version | RÃ´le |
|-------------|---------|------|
| React | 18+ | Framework UI |
| TypeScript | 5.9 | Typage statique |
| Vite | 7.2 | Build tool |
| Tailwind CSS | 4.1 | Styling utility-first |
| shadcn/ui | latest | Composants UI |
| TanStack Query | 5.90 | Server state |
| Zustand | 5.0 | Client state |
| Axios | 1.13 | HTTP client |
| Recharts | 3.7 | Graphiques |

#### FonctionnalitÃ©s

L'application React inclut **5 vues principales** :

1. **ChatView** : Conversation avec le chatbot RAG
   - Sessions persistentes
   - Affichage des sources avec scores
   - ParamÃ¨tre top_k configurable

2. **ApiExplorerView** : Test des endpoints API
   - Onglets Chat, Search, Health, Rebuild, Session
   - RequÃªtes en temps rÃ©el

3. **MonitoringView** : SantÃ© du systÃ¨me
   - Polling automatique du health endpoint
   - MÃ©triques (documents, sessions, embedding dim)

4. **RagasMetricsView** : Visualisation Ã©valuation
   - Upload de rapports JSON
   - Graphiques Recharts
   - Tableau de rÃ©sultats dÃ©taillÃ©s

5. **IndexManagementView** : Gestion FAISS
   - Informations sur l'index actuel
   - DÃ©clenchement rebuild avec progress

---

## IV. MODÃˆLES UTILISÃ‰S

### 4.1 Configuration LLM

**ModÃ¨le** : `mistral-small-latest`
- Provider : Mistral AI
- Version : Auto-updated (toujours derniÃ¨re version stable)
- Context window : 32K tokens
- Output max : 1000 tokens (~750 mots)

**ParamÃ¨tres de gÃ©nÃ©ration** :
```python
{
  "temperature": 0.7,      # CrÃ©ativitÃ© modÃ©rÃ©e
  "max_tokens": 1000,      # Limite longueur rÃ©ponse
  "top_p": 1.0,           # Nucleus sampling (toute la distribution)
  "stream": True           # Streaming pour UX
}
```

**Explication tempÃ©rature 0.7** :
- 0.0 : DÃ©terministe, rÃ©pÃ©titif
- 0.7 : Ã‰quilibre crÃ©ativitÃ©/consistance (recommandÃ©)
- 1.0+ : TrÃ¨s crÃ©atif, risque d'incohÃ©rence

### 4.2 Configuration Embeddings

**ModÃ¨le** : `mistral-embed`
- Dimension : 1024
- Langue : Multilingue (optimisÃ© franÃ§ais)
- Max input : ~8192 tokens
- Output : Vecteurs normalisÃ©s L2

**Batch processing** :
```python
{
  "batch_size": 32,        # Documents par requÃªte API
  "max_retries": 3,        # Tentatives en cas d'Ã©chec
  "timeout": 30            # Timeout par requÃªte (secondes)
}
```

**Performance** :
- Latence : ~200-300ms par batch de 32
- CoÃ»t : $0.0001/1K tokens (~500 Ã©vÃ©nements = $0.05)

### 4.3 Configuration Vector Index

**Type d'index** : `faiss.IndexFlatL2`
```python
{
  "index_type": "IndexFlatL2",       # Recherche exacte
  "dimension": 1024,                 # Correspond Ã  mistral-embed
  "metric_type": "L2",               # Distance euclidienne
  "normalize_vectors": True,         # Pour cosine similarity
  "num_documents": 497               # Taille actuelle
}
```

**Normalisation L2** :
```python
import faiss
faiss.normalize_L2(embeddings)  # ||v|| = 1
```

**Ã‰quivalence cosine â†” L2** (avec normalisation) :
```
similarity_cosine = 1 - (distance_L2 / 2)
```

**ParamÃ¨tres de recherche** :
```python
{
  "top_k": 5,                  # Nombre de rÃ©sultats (configurable 1-20)
  "min_similarity": 0.3        # Seuil de filtrage
}
```

### 4.4 Prompt Template

**Template systÃ¨me** (de `src/config/constants.py`) :
```python
SYSTEM_PROMPT_TEMPLATE = """Tu es un assistant intelligent qui aide les 
utilisateurs Ã  dÃ©couvrir des Ã©vÃ©nements culturels.

Contexte des Ã©vÃ©nements trouvÃ©s :
{context}

Question de l'utilisateur : {question}

Instructions :
- RÃ©ponds en franÃ§ais de maniÃ¨re naturelle et conversationnelle
- Recommande 2-3 Ã©vÃ©nements pertinents maximum
- Mentionne les informations pratiques (date, lieu, prix)
- Si aucun Ã©vÃ©nement ne correspond, propose des alternatives
- Sois concis mais informatif

RÃ©ponse :"""
```

**Variables de template** :
- `{context}` : Documents rÃ©cupÃ©rÃ©s par FAISS (formatÃ©s en texte)
- `{question}` : RequÃªte utilisateur originale

**Format du contexte** :
```
Titre: Concert de Jazz
Ville: Paris
Date: 20/01/2025 20:00
Prix: Gratuit
Description: Un concert de jazz exceptionnel...
URL: https://openagenda.com/...

---

Titre: Festival Ã‰lectro
...
```

---

## V. RÃ‰SULTATS OBSERVÃ‰S

### 5.1 MÃ©triques de Performance

**Source** : `data/processed/evaluation_results.json` + tests manuels

#### MÃ©triques Globales

| MÃ©trique | Valeur | Cible | Statut |
|----------|--------|-------|--------|
| **Latence moyenne** | 2.41s | <3.0s | âœ… PASS (+0.59s marge) |
| **Couverture mots-clÃ©s** | 81.5% | >80% | âœ… PASS (+1.5%) |
| **Classification accuracy** | 100% | ~95% | âœ… EXCELLENT (+5%) |
| **Test coverage code** | 85% | >80% | âœ… PASS (+5%) |
| **Questions RAG** | 9/12 (75%) | - | âœ… Good |
| **Questions conversationnelles** | 3/12 (25%) | - | âœ… Good |

#### Latence par CatÃ©gorie

| CatÃ©gorie | Nb Questions | Latence Moy. | Couverture Moy. | Statut |
|-----------|--------------|--------------|-----------------|--------|
| **Recherche simple** | 4 | 2.56s | 91.7% | âœ… |
| **Filtres multiples** | 2 | 3.28s | 100% | âš ï¸ Limite |
| **Recherche temporelle** | 2 | 2.97s | 50% | âš ï¸ |
| **Conversation** | 3 | 1.50s | 100% | âœ… |
| **Recherche style** | 1 | 1.69s | 66.7% | âš ï¸ |

**Observations** :
- âœ… Recherches simples excellentes (91.7% couverture)
- âœ… Filtres multiples parfait mais lent (3.28s)
- âš ï¸ TemporalitÃ© Ã  amÃ©liorer (50% couverture sur "Ã©tÃ©", "weekend")
- âœ… Conversations trÃ¨s rapides (1.5s, pas de FAISS)
- âš ï¸ Recherches par style Ã  amÃ©liorer (66.7%)

### 5.2 Analyse de Classification (needs_rag)

**Matrice de confusion** (12 questions test) :

|  | PrÃ©dit SEARCH | PrÃ©dit CHAT |
|---|---------------|-------------|
| **RÃ©el SEARCH** | 9 (TP) | 0 (FN) |
| **RÃ©el CHAT** | 0 (FP) | 3 (TN) |

**MÃ©triques** :
- Accuracy : **100%** (12/12)
- Precision : 100%
- Recall : 100%
- F1-score : 100%

**Exemples correctement classifiÃ©s** :

**SEARCH** :
- âœ… "Quels concerts de jazz sont prÃ©vus ce weekend Ã  Paris ?"
- âœ… "Y a-t-il des Ã©vÃ©nements gratuits pour enfants dimanche ?"
- âœ… "Je cherche une exposition d'art contemporain Ã  Marseille"

**CHAT** :
- âœ… "Bonjour, comment Ã§a va ?"
- âœ… "Merci beaucoup pour ton aide !"
- âœ… "Tu peux m'aider Ã  trouver des sorties ?"

**Importance** : Ã‰vite recherches FAISS inutiles (~1s Ã©conomisÃ© par requÃªte conversationnelle)

### 5.3 Exemples de RÃ©ponses

**Exemple 1** : Recherche simple
```
Question: "Quels concerts de jazz sont prÃ©vus ce weekend Ã  Paris ?"
Latence: 1.47s
Couverture: 100% (3/3)
Classification: SEARCH âœ…

RÃ©ponse:
"Salut ! Voici quelques concerts de jazz ce weekend Ã  Paris :
1. Paris Jazz Festival - Sam 18/01 Ã  20h, Parc Floral, Gratuit
2. Jazz au Caveau - Dim 19/01 Ã  19h30, Caveau de la Huchette, 15â‚¬
N'hÃ©site pas si tu veux plus d'infos ! ğŸ·"

Sources: 3 Ã©vÃ©nements (similaritÃ©: 0.87, 0.82, 0.76)
```

**Exemple 2** : Filtres multiples
```
Question: "Y a-t-il des Ã©vÃ©nements gratuits pour enfants dimanche ?"
Latence: 3.88s âš ï¸
Couverture: 100% (3/3)
Classification: SEARCH âœ…

RÃ©ponse:
"Oui, voici quelques Ã©vÃ©nements gratuits pour enfants ce dimanche :
1. Atelier CrÃ©atif Enfants - Dim 19/01 Ã  14h, BibliothÃ¨que Municipale
2. Spectacle de Marionnettes - Dim 19/01 Ã  16h, Parc BorÃ©ly
C'est des activitÃ©s sympas pour les petits ! ğŸ˜Š"

Sources: 3 Ã©vÃ©nements (similaritÃ©: 0.91, 0.85, 0.73)
```

**Exemple 3** : Conversation
```
Question: "Bonjour, comment Ã§a va ?"
Latence: 1.98s
Classification: CHAT âœ…

RÃ©ponse:
"Salut ! Je vais trÃ¨s bien, merci ! ğŸ˜Š
Je suis lÃ  pour t'aider Ã  trouver des Ã©vÃ©nements culturels sympas.
Tu cherches quelque chose en particulier ?"

Sources: Aucune (pas de RAG)
```

### 5.4 Analyse de QualitÃ©

**Points forts** :
- âœ… RÃ©ponses naturelles en franÃ§ais (ton conversationnel)
- âœ… Informations pratiques complÃ¨tes (date, lieu, prix, URL)
- âœ… Classification fiable (100% accuracy)
- âœ… Sources vÃ©rifiables (liens Open Agenda)
- âœ… Suggestions alternatives quand pas de match
- âœ… Latence respectÃ©e (2.41s moyenne < 3s cible)

**Limitations identifiÃ©es** :
- âš ï¸ Filtres temporels complexes ("Ã©tÃ©", "weekend") parfois incomplets
- âš ï¸ Genres musicaux spÃ©cifiques ("techno", "electro") parfois manquÃ©s
- âš ï¸ Pas de reformulation de requÃªte si aucun rÃ©sultat
- âš ï¸ Latence variable (1.5s CHAT vs 3.9s SEARCH multi-filtres)

---

## VI. PISTES D'AMÃ‰LIORATION

### 6.1 Performance

**Optimisation FAISS** :
- **Actuel** : IndexFlatL2 (recherche exacte, O(n))
- **AmÃ©lioration** : IndexIVFFlat pour >10K Ã©vÃ©nements
  - Recherche approximative (95-98% recall)
  - 10-100x plus rapide
  - Trade-off acceptable pour production
  
```python
# Configuration IVF recommandÃ©e
nlist = 100  # Nombre de clusters
index = faiss.IndexIVFFlat(quantizer, dimension, nlist)
index.train(embeddings)  # EntraÃ®nement requis
```

**Caching stratÃ©gies** :
- Cache embeddings pour requÃªtes frÃ©quentes (Redis)
  - Ã‰vite appels API Mistral rÃ©pÃ©tÃ©s
  - RÃ©duction 50% du coÃ»t pour queries rÃ©pÃ©tÃ©es
- Cache rÃ©ponses LLM (TTL 1h)
  - Pour requÃªtes identiques
  - Trade-off fraÃ®cheur vs performance

**Batch optimizations** :
- Batch size dynamique basÃ© sur GPU memory
- Streaming embeddings vers FAISS (rÃ©duit RAM)

### 6.2 FonctionnalitÃ©

**Session Persistence** : âœ… **IMPLÃ‰MENTÃ‰**
- **Avant** : In-memory (perdu au restart)
- **Maintenant** : PostgreSQL avec SQLAlchemy async
- **ModÃ¨les** : `SessionModel`, `MessageModel` avec JSONB
- **BÃ©nÃ©fices obtenus** :
  - Sessions persistent entre redÃ©marrages
  - Historique stockÃ© avec sources et latence
  - Multi-instance ready
  - Analytics possibles sur requÃªtes

**Frontend React** : âœ… **IMPLÃ‰MENTÃ‰**
- Application complÃ¨te avec 5 vues
- shadcn/ui + Tailwind CSS
- TanStack Query + Zustand

**Authentification Utilisateurs** :
- OAuth2 (Google, GitHub)
- JWT tokens pour stateless auth
- Per-user query history et prÃ©fÃ©rences
- Rate limiting par utilisateur

**Support Multi-Langues** :
- Anglais, Espagnol (en plus du franÃ§ais)
- Language detection dans query
- Multilingual embeddings dÃ©jÃ  supportÃ©s (Mistral Embed)

**Filtres AvancÃ©s** :
- Prix range slider (0-50â‚¬)
- Distance radius from location (5km, 10km, 20km)
- Event duration (1h, 2h+, full day)
- Accessibility filters (wheelchair, hearing loop)

### 6.3 QualitÃ© RAG

**Reranking avec Cross-Encoder** :
- **Actuel** : Single-pass retrieval (bi-encoder)
- **AmÃ©lioration** : Two-stage pipeline
  1. FAISS retrieves top-20 (bi-encoder rapide)
  2. Cross-encoder reranks to top-5 (lent mais prÃ©cis)
- **Gain attendu** : +10-15% relevance

**Hybrid Search** :
- Combiner semantic (FAISS) + keyword (BM25/Elasticsearch)
- Weighted: 0.7 Ã— semantic + 0.3 Ã— keyword
- Meilleur pour exact name matches ("Festival d'Avignon")

**Query Expansion** :
- LLM-based query reformulation
- Extract filters: "weekend" â†’ "samedi" OR "dimanche"
- Expand genres: "jazz" â†’ "jazz", "blues", "soul"

**Vector Memory** :
- Store conversation history as embeddings
- Semantic search over past exchanges
- Better long-term context preservation

### 6.4 OpÃ©rations

**Monitoring Production** :
- Prometheus metrics (latency, error rate, API calls)
- Grafana dashboards
- Alerts si latency >5s ou error rate >5%

**CI/CD Pipeline** :
- GitHub Actions :
  - pytest on every PR
  - Black/Ruff checks
  - Docker build and push
  - Deploy to staging on merge to main

**Automated Index Refresh** :
- Cron job to fetch new events daily
- Incremental index updates (FAISS add_with_ids)
- Blue-green deployment pour zero-downtime

**A/B Testing Framework** :
- Test prompt variations
- Compare embedding models
- Measure impact of reranking

### 6.5 Priorisation (Mise Ã  Jour FÃ©vrier 2026)

**âœ… COMPLÃ‰TÃ‰** :
1. ~~Session persistence~~ â†’ PostgreSQL + SQLAlchemy async
2. ~~Frontend React~~ â†’ Application complÃ¨te avec 5 vues
3. ~~CI/CD pipeline~~ â†’ GitHub Actions (lint, build, docker)

**High Priority** (Restant) :
1. Monitoring + alerting (Prometheus/Grafana)
2. FAISS IVF pour scalabilitÃ© (>10K events)
3. Rate limiting API

**Medium Priority** (Quality improvement) :
4. Reranking (cross-encoder)
5. Hybrid search (BM25 + FAISS)
6. Advanced filters (prix, distance, durÃ©e)
7. Query expansion

**Low Priority** (Nice-to-have) :
8. Multi-language support (EN, ES)
9. User authentication (OAuth2)
10. A/B testing framework
11. Vector memory

**Estimation effort** (1 dÃ©veloppeur) :
- High priority restant : 1-2 semaines
- Medium priority : 3-4 semaines
- Low priority : 2-3 semaines

---

## VII. CONCLUSION

### 7.1 RÃ©alisations

Ce projet dÃ©montre une implÃ©mentation complÃ¨te et fonctionnelle d'un systÃ¨me RAG production-ready :

**SuccÃ¨s techniques** :
- âœ… Architecture 4 couches bien sÃ©parÃ©e
- âœ… Pipeline RAG complet (classification, retrieval, generation)
- âœ… Performance cibles atteintes (latence, relevance, accuracy)
- âœ… Tests complets (85% coverage, 3 niveaux)
- âœ… Documentation professionnelle
- âœ… DÃ©ploiement Docker ready

**SuccÃ¨s fonctionnels** :
- âœ… Classification intelligente SEARCH vs CHAT (100% accuracy)
- âœ… Recherche sÃ©mantique pertinente (81.5% keyword coverage)
- âœ… RÃ©ponses naturelles en franÃ§ais
- âœ… Sources vÃ©rifiables citÃ©es
- âœ… Session management fonctionnel

### 7.2 Ã‰valuation Production-Readiness

| Aspect | Statut | Notes |
|--------|--------|-------|
| **Functionality** | âœ… Ready | RAG + React frontend + API complÃ¨te |
| **Performance** | âœ… Ready | Meets latency/relevance targets |
| **Reliability** | âœ… Ready | PostgreSQL sessions + error handling |
| **Scalability** | âš ï¸ Partial | Works <1K events, needs IVF for scale |
| **Security** | âš ï¸ Partial | Basic validation, needs auth/rate limiting |
| **Observability** | âš ï¸ Partial | Frontend monitoring, needs Prometheus |
| **Deployment** | âœ… Ready | Docker + compose + CI/CD GitHub Actions |

**Recommandation** : Ready for **production MVP deployment**. Ajouter Prometheus/Grafana et authentification pour production complÃ¨te.

### 7.3 LeÃ§ons Apprises

**Techniques** :
- Direct SDK integration > abstraction frameworks (pour cette Ã©chelle)
- FAISS parfait pour <1M documents
- Mistral AI excellent pour franÃ§ais
- Query classification critique pour UX (Ã©vite RAG inutiles)
- Streaming responses amÃ©liore significativement UX

**MÃ©thodologiques** :
- Jupyter notebooks excellents pour expÃ©rimentation
- TDD pays off (dÃ©tection bugs prÃ©coce)
- RAGAS framework valuable mais requires labeled data
- Documentation from day 1 crucial

**Architecturales** :
- SÃ©paration prÃ©sentation/logique/donnÃ©es facilite tests
- Pydantic validation sauve beaucoup de bugs
- Background tasks essentiels pour opÃ©rations longues
- PostgreSQL pour sessions = scalabilitÃ© et persistence
- Monorepo (backend/frontend) simplifie le dÃ©ploiement unifiÃ©

### 7.4 Prochaines Ã‰tapes

**âœ… ComplÃ©tÃ©** :
- ~~Session persistence~~ â†’ PostgreSQL implÃ©mentÃ©
- ~~CI/CD pipeline~~ â†’ GitHub Actions configurÃ©
- ~~Frontend web React~~ â†’ Application complÃ¨te

**Court terme (1 mois)** :
1. Ajouter Prometheus + Grafana monitoring
2. Add temporal filter expansion ("Ã©tÃ©" â†’ months)
3. Rate limiting API

**Moyen terme (3 mois)** :
4. Implement reranking (cross-encoder)
5. Scale to 10K+ events (FAISS IVF)
6. Add user authentication (OAuth2)
7. Advanced filtering (price, distance)

**Long terme (6+ mois)** :
8. Multi-language support (EN, ES)
9. Automated daily index refresh
10. A/B testing framework

---

## ANNEXES

Voir le dossier `annexes/` pour :
- **[architecture-complete.md](annexes/architecture-complete.md)** : Architecture systÃ¨me dÃ©taillÃ©e
- **[choix-technologiques.md](annexes/choix-technologiques.md)** : Comparaisons technologiques approfondies
- **[ameliorations-futures.md](annexes/ameliorations-futures.md)** : Roadmap dÃ©taillÃ©e avec estimations
- **[schemas/](annexes/schemas/)** : Diagrammes d'architecture ASCII

---

## RÃ‰FÃ‰RENCES

### Documentation

- **README.md** : Vue d'ensemble du projet
- **ARCHITECTURE.md** : Architecture systÃ¨me
- **COMPRENDRE_LE_RAG.md** : Guide pÃ©dagogique RAG
- **GUIDE_DEMARRAGE.md** : Installation et dÃ©marrage
- **REFERENCE_API.md** : Documentation API REST

### Sources Externes

- Mistral AI Documentation : https://docs.mistral.ai/
- FAISS Documentation : https://github.com/facebookresearch/faiss
- FastAPI Documentation : https://fastapi.tiangolo.com/
- Streamlit Documentation : https://docs.streamlit.io/
- Open Agenda API : https://openagenda.com/developers
- RAGAS Framework : https://docs.ragas.io/

### Articles de RÃ©fÃ©rence

- Lewis et al. (2020) : "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
- Johnson et al. (2019) : "Billion-scale similarity search with GPUs" (FAISS)
- Reimers & Gurevych (2019) : "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"

---

**Date de rÃ©daction** : 4 FÃ©vrier 2026 (v2.0)  
**Auteur** : Pierre Pluton  
**Contact** : pierre.pluton@outlook.fr  
**Repository** : https://github.com/[username]/OC7---Projet-RAG-Assistant-Intelligent-Events

---

<div align="center">

**Fait avec â¤ï¸ et â˜• dans le cadre du parcours OpenClassrooms**

ğŸ­ **RAG Events Assistant** - DÃ©couvrez des Ã©vÃ©nements culturels avec l'IA

</div>
