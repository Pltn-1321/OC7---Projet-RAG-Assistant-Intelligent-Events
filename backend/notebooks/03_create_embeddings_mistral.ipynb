{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Cr√©ation des Embeddings\n",
    "\n",
    "G√©n√©ration des vecteurs d'embeddings avec **Mistral AI** ou **sentence-transformers**.\n",
    "\n",
    "**√âtapes :**\n",
    "\n",
    "1. Configuration du provider\n",
    "2. G√©n√©ration des vecteurs\n",
    "3. Validation et analyse\n",
    "4. Export pour FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration OK\n",
      "üìä Provider d'embeddings : mistral\n",
      "üß† Mod√®le : mistral-embed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.config.constants import PROCESSED_DATA_DIR\n",
    "from src.config.settings import settings\n",
    "\n",
    "print(\"‚úÖ Configuration OK\")\n",
    "print(f\"üìä Provider d'embeddings : {settings.embedding_provider}\")\n",
    "print(f\"üß† Mod√®le : {settings.embedding_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Chargement des Donn√©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä 497 documents charg√©s\n",
      "\n",
      "üìã Exemple de contenu √† vectoriser :\n",
      "Titre: Formation Civique et Citoyenne \"Cadre de vie et architecture\"\n",
      "Ville: Marseille\n",
      "Date: Du 14/06/2022 √† 07:00 au 31/12/2025 √† 22:59\n",
      "Description: Formation obligatoire √† l'attention des volontaires de Service Civique, propos√©e par la MAV PACA.\n",
      "Adresse: 12 Bd Th√©odore Thurner 13006 Marseille\n"
     ]
    }
   ],
   "source": [
    "# Charger les documents pr√©trait√©s\n",
    "documents_path = PROCESSED_DATA_DIR / \"rag_documents.json\"\n",
    "\n",
    "with open(documents_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "print(f\"üìä {len(documents)} documents charg√©s\")\n",
    "print(f\"\\nüìã Exemple de contenu √† vectoriser :\")\n",
    "print(documents[0][\"content\"][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Classe d'Embeddings Unifi√©e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classe EmbeddingGenerator d√©finie\n"
     ]
    }
   ],
   "source": [
    "from mistralai import Mistral\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"G√©n√©rateur d'embeddings unifi√© (Mistral ou SentenceTransformers).\"\"\"\n",
    "\n",
    "    def __init__(self, provider: str = None, model_name: str = None, api_key: str = None):\n",
    "        self.provider = provider or settings.embedding_provider\n",
    "        self.model_name = model_name or settings.embedding_model\n",
    "\n",
    "        print(f\"üîÑ Initialisation du provider : {self.provider}\")\n",
    "\n",
    "        if self.provider == \"mistral\":\n",
    "            if not api_key and not settings.mistral_api_key:\n",
    "                raise ValueError(\"Mistral API key required\")\n",
    "\n",
    "            self.client = Mistral(api_key=api_key or settings.mistral_api_key)\n",
    "            self.dimension = 1024\n",
    "            print(f\"‚úÖ Mistral client initialis√© (dimension: {self.dimension})\")\n",
    "\n",
    "        else:  # sentence-transformers\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            self.dimension = self.model.get_sentence_embedding_dimension()\n",
    "            print(f\"‚úÖ SentenceTransformer charg√© (dimension: {self.dimension})\")\n",
    "\n",
    "    def encode(\n",
    "        self, texts: List[str], batch_size: int = 32, show_progress: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Encode une liste de textes en embeddings.\"\"\"\n",
    "\n",
    "        if self.provider == \"mistral\":\n",
    "            return self._encode_mistral(texts, batch_size, show_progress)\n",
    "        else:\n",
    "            return self._encode_sentence_transformer(texts, batch_size, show_progress)\n",
    "\n",
    "    def _encode_mistral(self, texts: List[str], batch_size: int, show_progress: bool) -> np.ndarray:\n",
    "        \"\"\"Encode avec Mistral API.\"\"\"\n",
    "        embeddings = []\n",
    "\n",
    "        iterator = range(0, len(texts), batch_size)\n",
    "        if show_progress:\n",
    "            iterator = tqdm(iterator, desc=\"üß† Mistral Embeddings\")\n",
    "\n",
    "        for i in iterator:\n",
    "            batch = texts[i : i + batch_size]\n",
    "\n",
    "            # Appel API Mistral\n",
    "            response = self.client.embeddings.create(model=self.model_name, inputs=batch)\n",
    "\n",
    "            # Extraire les embeddings\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "\n",
    "        return np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "    def _encode_sentence_transformer(\n",
    "        self, texts: List[str], batch_size: int, show_progress: bool\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Encode avec SentenceTransformer.\"\"\"\n",
    "        return self.model.encode(\n",
    "            texts, batch_size=batch_size, show_progress_bar=show_progress, convert_to_numpy=True\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Classe EmbeddingGenerator d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ G√©n√©ration des Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initialisation du provider : mistral\n",
      "‚úÖ Mistral client initialis√© (dimension: 1024)\n",
      "üß† G√©n√©ration de 497 embeddings...\n",
      "‚ö†Ô∏è Cela peut prendre plusieurs minutes\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cff63845d7a4caeba987f494a703f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Mistral Embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Embeddings g√©n√©r√©s\n",
      "üìê Shape : (497, 1024)\n",
      "üíæ Taille : 1.94 MB\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le g√©n√©rateur\n",
    "generator = EmbeddingGenerator()\n",
    "\n",
    "# Extraire les contenus\n",
    "contents = [doc[\"content\"] for doc in documents]\n",
    "\n",
    "print(f\"üß† G√©n√©ration de {len(contents)} embeddings...\")\n",
    "print(\"‚ö†Ô∏è Cela peut prendre plusieurs minutes\\n\")\n",
    "\n",
    "# G√©n√©rer les embeddings\n",
    "embeddings = generator.encode(contents, batch_size=32, show_progress=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Embeddings g√©n√©r√©s\")\n",
    "print(f\"üìê Shape : {embeddings.shape}\")\n",
    "print(f\"üíæ Taille : {embeddings.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation des embeddings :\n",
      "  Nombre : 497\n",
      "  Dimension : 1024\n",
      "  Type : float32\n",
      "  Valeurs nulles : 0\n",
      "  Min : -0.1210\n",
      "  Max : 0.1220\n",
      "  Moyenne : -0.0002\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier la qualit√© des embeddings\n",
    "print(\"‚úÖ Validation des embeddings :\")\n",
    "print(f\"  Nombre : {len(embeddings)}\")\n",
    "print(f\"  Dimension : {embeddings.shape[1]}\")\n",
    "print(f\"  Type : {embeddings.dtype}\")\n",
    "print(f\"  Valeurs nulles : {np.isnan(embeddings).sum()}\")\n",
    "print(f\"  Min : {embeddings.min():.4f}\")\n",
    "print(f\"  Max : {embeddings.max():.4f}\")\n",
    "print(f\"  Moyenne : {embeddings.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Test de Similarit√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Matrice de similarit√© (5 premiers documents) :\n",
      "\n",
      "Indices des documents :\n",
      "0: Formation Civique et Citoyenne \"Cadre de vie et ar\n",
      "1: \"CONSTRUCTEURS DE DEMAIN, D√©couverte ludique des m\n",
      "2: \"Viv(r)e l'architecture, un architecte dans la cla\n",
      "3: Exposition \"Hors Site (mais pas hors sol)\"\n",
      "4: Devenez conducteur de bus - POEI RTM\n",
      "\n",
      "üìä Similarit√©s :\n",
      "[[1.    0.872 0.902 0.85  0.84 ]\n",
      " [0.872 1.    0.924 0.873 0.838]\n",
      " [0.902 0.924 1.    0.876 0.836]\n",
      " [0.85  0.873 0.876 1.    0.814]\n",
      " [0.84  0.838 0.836 0.814 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tester sur les 5 premiers documents\n",
    "sample_embeddings = embeddings[:5]\n",
    "similarity_matrix = cosine_similarity(sample_embeddings)\n",
    "\n",
    "print(\"üîç Matrice de similarit√© (5 premiers documents) :\")\n",
    "print(\"\\nIndices des documents :\")\n",
    "for i in range(5):\n",
    "    print(f\"{i}: {documents[i]['title'][:50]}\")\n",
    "\n",
    "print(\"\\nüìä Similarit√©s :\")\n",
    "print(similarity_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Embeddings : /Users/ppluton/Documents/Repositories/OC7---Projet-RAG-Assistant-Intelligent-Events/data/processed/embeddings/embeddings.npy\n",
      "üíæ M√©tadonn√©es : /Users/ppluton/Documents/Repositories/OC7---Projet-RAG-Assistant-Intelligent-Events/data/processed/embeddings/metadata.json\n",
      "\n",
      "‚úÖ Export termin√© !\n",
      "\n",
      "‚û°Ô∏è Prochaine √©tape : Notebook 04 - Construction de l'index FAISS\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er le dossier embeddings\n",
    "embeddings_dir = PROCESSED_DATA_DIR / \"embeddings\"\n",
    "embeddings_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export embeddings (numpy)\n",
    "embeddings_path = embeddings_dir / \"embeddings.npy\"\n",
    "np.save(embeddings_path, embeddings)\n",
    "\n",
    "# Export m√©tadonn√©es\n",
    "metadata_path = embeddings_dir / \"metadata.json\"\n",
    "metadata = {\n",
    "    \"provider\": settings.embedding_provider,\n",
    "    \"model_name\": settings.embedding_model,\n",
    "    \"embedding_dim\": embeddings.shape[1],\n",
    "    \"num_documents\": len(embeddings),\n",
    "    \"document_ids\": [doc[\"id\"] for doc in documents],\n",
    "}\n",
    "\n",
    "with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"üíæ Embeddings : {embeddings_path}\")\n",
    "print(f\"üíæ M√©tadonn√©es : {metadata_path}\")\n",
    "print(f\"\\n‚úÖ Export termin√© !\")\n",
    "print(f\"\\n‚û°Ô∏è Prochaine √©tape : Notebook 04 - Construction de l'index FAISS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC7---Projet-RAG-Assistant-Intelligent-Events",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
