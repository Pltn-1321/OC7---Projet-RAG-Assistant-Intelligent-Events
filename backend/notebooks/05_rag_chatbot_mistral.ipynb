{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Syst√®me RAG Complet avec Mistral AI\n",
    "\n",
    "Chatbot conversationnel avec recherche s√©mantique et g√©n√©ration de r√©ponses via **Mistral LLM**.\n",
    "\n",
    "**√âtapes :**\n",
    "\n",
    "1. Chargement du syst√®me RAG\n",
    "2. Configuration du LLM Mistral\n",
    "3. Tests conversationnels\n",
    "4. √âvaluation qualitative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration OK\n",
      "üß† Provider : mistral\n",
      "üí¨ LLM : mistral-small-latest\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import faiss\n",
    "from mistralai import Mistral\n",
    "\n",
    "from src.config.constants import PROCESSED_DATA_DIR\n",
    "from src.config.settings import settings\n",
    "\n",
    "print(\"‚úÖ Configuration OK\")\n",
    "print(f\"üß† Provider : {settings.embedding_provider}\")\n",
    "print(f\"üí¨ LLM : {settings.llm_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Syst√®me RAG avec Mistral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classe EmbeddingGenerator d√©finie\n"
     ]
    }
   ],
   "source": [
    "# Importer la classe d'embeddings du notebook 03\n",
    "from mistralai import Mistral\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"G√©n√©rateur d'embeddings unifi√© (copi√© du notebook 03).\"\"\"\n",
    "\n",
    "    def __init__(self, provider: str = None, model_name: str = None, api_key: str = None):\n",
    "        self.provider = provider or settings.embedding_provider\n",
    "        self.model_name = model_name or settings.embedding_model\n",
    "\n",
    "        if self.provider == \"mistral\":\n",
    "            if not api_key and not settings.mistral_api_key:\n",
    "                raise ValueError(\"Mistral API key required\")\n",
    "            self.client = Mistral(api_key=api_key or settings.mistral_api_key)\n",
    "            self.dimension = 1024\n",
    "        else:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            self.dimension = self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "    def encode_single(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Encode un seul texte.\"\"\"\n",
    "        if self.provider == \"mistral\":\n",
    "            response = self.client.embeddings.create(model=self.model_name, inputs=[text])\n",
    "            return np.array([response.data[0].embedding], dtype=np.float32)\n",
    "        else:\n",
    "            return self.model.encode([text], convert_to_numpy=True)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Classe EmbeddingGenerator d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initialisation...\n",
      "\n",
      "üîÑ Initialisation du syst√®me RAG...\n",
      "  ‚úÖ Index FAISS charg√© (497 vecteurs)\n",
      "  ‚úÖ 497 documents charg√©s\n",
      "  ‚úÖ G√©n√©rateur d'embeddings charg√©\n",
      "  ‚úÖ Client Mistral LLM charg√©\n",
      "\n",
      "‚úÖ Syst√®me RAG pr√™t !\n"
     ]
    }
   ],
   "source": [
    "class MistralEventsRAG:\n",
    "    \"\"\"Syst√®me RAG pour √©v√©nements avec Mistral AI.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"üîÑ Initialisation du syst√®me RAG...\")\n",
    "\n",
    "        # Chemins\n",
    "        index_dir = PROCESSED_DATA_DIR / \"faiss_index\"\n",
    "\n",
    "        # Charger configuration\n",
    "        with open(index_dir / \"config.json\", \"r\") as f:\n",
    "            self.config = json.load(f)\n",
    "\n",
    "        # Charger index FAISS\n",
    "        self.index = faiss.read_index(str(index_dir / \"events.index\"))\n",
    "        print(f\"  ‚úÖ Index FAISS charg√© ({self.index.ntotal} vecteurs)\")\n",
    "\n",
    "        # Charger documents\n",
    "        documents_path = PROCESSED_DATA_DIR / \"rag_documents.json\"\n",
    "        with open(documents_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.documents = json.load(f)\n",
    "        print(f\"  ‚úÖ {len(self.documents)} documents charg√©s\")\n",
    "\n",
    "        # Charger g√©n√©rateur d'embeddings\n",
    "        self.embedding_generator = EmbeddingGenerator()\n",
    "        print(f\"  ‚úÖ G√©n√©rateur d'embeddings charg√©\")\n",
    "\n",
    "        # Charger client Mistral pour le LLM\n",
    "        self.mistral_client = Mistral(api_key=settings.mistral_api_key)\n",
    "        print(f\"  ‚úÖ Client Mistral LLM charg√©\")\n",
    "\n",
    "        print(\"\\n‚úÖ Syst√®me RAG pr√™t !\")\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Recherche s√©mantique d'√©v√©nements.\"\"\"\n",
    "\n",
    "        # Encoder la requ√™te\n",
    "        query_embedding = self.embedding_generator.encode_single(query)\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "\n",
    "        # Recherche\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "\n",
    "        # Formater les r√©sultats\n",
    "        results = []\n",
    "        for idx, dist in zip(indices[0], distances[0]):\n",
    "            doc = self.documents[idx]\n",
    "            results.append(\n",
    "                {\"document\": doc, \"similarity\": float(1 - dist), \"distance\": float(dist)}\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def generate_response(self, query: str, results: List[Dict]) -> str:\n",
    "        \"\"\"G√©n√®re une r√©ponse conversationnelle avec Mistral LLM.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return \"Je n'ai trouv√© aucun √©v√©nement correspondant √† votre recherche. Pouvez-vous reformuler ou pr√©ciser votre demande ?\"\n",
    "\n",
    "        # Construire le contexte pour le LLM\n",
    "        context = \"Voici les √©v√©nements pertinents :\\n\\n\"\n",
    "        for i, result in enumerate(results, 1):\n",
    "            doc = result[\"document\"]\n",
    "            context += f\"√âv√©nement {i}:\\n{doc['content']}\\n\\n\"\n",
    "\n",
    "        # Prompt pour le LLM\n",
    "        system_prompt = \"\"\"Tu es un assistant sp√©cialis√© dans la recommandation d'√©v√©nements culturels.\n",
    "Ton r√¥le est d'aider les utilisateurs √† trouver des √©v√©nements qui correspondent √† leurs int√©r√™ts.\n",
    "R√©ponds de mani√®re naturelle, conviviale et concise en fran√ßais.\n",
    "Base tes r√©ponses uniquement sur les √©v√©nements fournis dans le contexte.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Question de l'utilisateur : {query}\n",
    "\n",
    "{context}\n",
    "\n",
    "R√©ponds √† la question de l'utilisateur en te basant sur ces √©v√©nements.\n",
    "Pr√©sente 2-3 √©v√©nements maximum de mani√®re attrayante avec :\n",
    "- Le titre\n",
    "- La ville\n",
    "- Une br√®ve description\n",
    "- Le lien si disponible\n",
    "\n",
    "Sois concis et engageant.\"\"\"\n",
    "\n",
    "        # Appel √† Mistral LLM\n",
    "        response = self.mistral_client.chat.complete(\n",
    "            model=settings.llm_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=settings.llm_temperature,\n",
    "            max_tokens=settings.max_tokens,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def chat(self, query: str, top_k: int = 5) -> str:\n",
    "        \"\"\"Interface conversationnelle compl√®te.\"\"\"\n",
    "        results = self.search(query, top_k)\n",
    "        return self.generate_response(query, results)\n",
    "\n",
    "\n",
    "# Initialiser le syst√®me\n",
    "print(\"üöÄ Initialisation...\\n\")\n",
    "rag = MistralEventsRAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Tests Conversationnels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ User: Je cherche des concerts de jazz\n",
      "\n",
      "ü§ñ Assistant:\n",
      "Voici quelques concerts de jazz qui pourraient t'int√©resser :\n",
      "\n",
      "1. **Concert au mus√©e Cantini avec Oliver Foster**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Un concert intimiste au mus√©e Cantini, parfait pour les amateurs de jazz.\n",
      "   - **Date** : 17/05/2025 de 17:00 √† 20:00\n",
      "\n",
      "2. **Black sound tricks & Friends**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Un √©v√©nement festif pour la F√™te de la Musique 2025, avec une programmation √©clectique.\n",
      "   - **Date** : 21/06/2025 de 10:00 √† 22/06/2025 √† 00:00\n",
      "\n",
      "Profite bien de ces moments musicaux !\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : Recherche par type\n",
    "print(\"üí¨ User: Je cherche des concerts de jazz\\n\")\n",
    "response = rag.chat(\"concerts de jazz\")\n",
    "print(f\"ü§ñ Assistant:\\n{response}\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ User: Quels √©v√©nements √† Marseille ce week-end ?\n",
      "\n",
      "ü§ñ Assistant:\n",
      "Voici quelques √©v√©nements √† ne pas manquer √† Marseille :\n",
      "\n",
      "1. **\"Si Victor m'√©tait cont√©\"**\n",
      "   - **Date** : Du 20/09/2025 √† 18:30 au 21/09/2025 √† 16:30\n",
      "   - **Description** : Plongez dans un spectacle captivant m√™lant contes, l√©gendes chevaleresques, chants gr√©goriens et lyriques, danses et apparitions fantomatiques. Un voyage √† travers quinze si√®cles d'histoire m√©diterran√©enne.\n",
      "   - **Adresse** : Place Saint-Victor, 13007 Marseille, France\n",
      "\n",
      "2. **\"√Ä la rencontre de celles et ceux qui r√©inventent la Citadelle de Marseille\"**\n",
      "   - **Date** : Du 20/09/2025 √† 10:00 au 21/09/2025 √† 16:00\n",
      "   - **Description** : D√©couvrez les projets innovants qui animent le fort Saint-Nicolas lors des Journ√©es Europ√©ennes du Patrimoine 2025.\n",
      "   - **Adresse** : Mont√©e du Souvenir Fran√ßais, 13007 Marseille\n",
      "\n",
      "3. **\"Veill√©e de paroles et musiques\"**\n",
      "   - **Date** : Du 21/07/2025 √† 07:30 au 31/07/2025 √† 15:30\n",
      "   - **Description** : Rejoignez le collectif Transbordeur pour une veill√©e partag√©e o√π chacun peut dire son nom et ceux qui lui sont chers, autour de musiques et de paroles.\n",
      "   - **Adresse** : 8 traverse Charles Susini, 13013 Marseille\n",
      "\n",
      "Profitez bien de ces √©v√©nements marseillais !\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2 : Recherche par ville\n",
    "print(\"üí¨ User: Quels √©v√©nements √† Marseille ce week-end ?\\n\")\n",
    "response = rag.chat(\"√©v√©nements √† Marseille\")\n",
    "print(f\"ü§ñ Assistant:\\n{response}\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ User: Des activit√©s cr√©atives pour mes enfants\n",
      "\n",
      "ü§ñ Assistant:\n",
      "Voici quelques activit√©s cr√©atives pour enfants √† Marseille :\n",
      "\n",
      "1. **Atelier pratiques artistiques**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Un projet de sensibilisation et d'exp√©rimentation autour de la peinture et du volume avec l'argile, sp√©cialement con√ßu pour les enfants.\n",
      "   - **Adresse** : 5 Traverse Paul Converset 13014 Marseille\n",
      "\n",
      "2. **Rouvrir le monde / Cadavre exquis anim√© / Clara Buffey**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Une exp√©rience collaborative o√π les enfants cr√©ent ensemble un court m√©trage d'animation en combinant leurs dessins individuels.\n",
      "   - **Adresse** : 7 Rue Pascal Posado, 13015 Marseille\n",
      "\n",
      "3. **Ateliers d'√©criture cr√©ative avec le Labo des histoires**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Des ateliers d'√©criture cr√©ative pour les enfants, organis√©s en collaboration avec le Labo des histoires et l'auteur dramaturge Lionel Parrini.\n",
      "   - **Adresse** : bd de la Corderie 13007 Marseille\n",
      "\n",
      "Profitez de ces activit√©s pour stimuler la cr√©ativit√© de vos enfants !\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3 : Recherche pour enfants\n",
    "print(\"üí¨ User: Des activit√©s cr√©atives pour mes enfants\\n\")\n",
    "response = rag.chat(\"activit√©s cr√©atives pour enfants\")\n",
    "print(f\"ü§ñ Assistant:\\n{response}\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ User: Je m'int√©resse √† l'art contemporain\n",
      "\n",
      "ü§ñ Assistant:\n",
      "Voici quelques expositions d'art contemporain √† ne pas manquer √† Marseille :\n",
      "\n",
      "1. **Exposition d'art contemporain**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : D√©couvrez une galerie d'art contemporain avec un showroom permanent pr√®s du Vieux-Port. La galerie abrite √©galement un atelier d'artistes.\n",
      "   - **Adresse** : 25, cours d'Estienne d'Orves 13001 Marseille\n",
      "\n",
      "2. **Friche la Belle de Mai : Les expositions d'art contemporain**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Plongez dans l'univers de Madison Bycroft avec l'exposition ¬´ Les mensonges du m√©t√©orologue ¬ª.\n",
      "   - **Adresse** : 41 rue Jobin 13003 Marseille\n",
      "\n",
      "3. **Exposition \"Hors Site (mais pas hors sol)\"**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Une exposition fascinante sur la pr√©fabrication en architecture.\n",
      "   - **Adresse** : 12 boulevard Th√©odore Thurner 13006 Marseille\n",
      "\n",
      "Profitez de ces √©v√©nements culturels pour explorer l'art contemporain √† Marseille !\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 4 : Recherche culturelle\n",
    "print(\"üí¨ User: Je m'int√©resse √† l'art contemporain\\n\")\n",
    "response = rag.chat(\"expositions art contemporain\")\n",
    "print(f\"ü§ñ Assistant:\\n{response}\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ User: Des √©v√©nements gratuits ce week-end\n",
      "\n",
      "ü§ñ Assistant:\n",
      "Voici quelques √©v√©nements gratuits √† ne pas manquer √† Marseille :\n",
      "\n",
      "1. **Les expositions en acc√®s libre tout le weekend**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Profitez d'un acc√®s gratuit aux expositions du J4 et du Fort Saint-Jean, comme ¬´ Lire le ciel ¬ª et ¬´ Amazighes ¬ª.\n",
      "   - **Date** : Du 20/09/2025 √† 08:00 au 21/09/2025 √† 17:00\n",
      "\n",
      "2. **Visites guid√©es gratuites √† la d√©couverte du CICRP**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : D√©couvrez les b√¢timents et les ateliers de restauration du Centre Interdisciplinaire de Conservation et de Restauration du Patrimoine.\n",
      "   - **Date** : Du 20/09/2025 √† 07:30 au 20/09/2025 √† 14:00\n",
      "\n",
      "3. **Veill√©e de paroles et musiques**\n",
      "   - **Ville** : Marseille\n",
      "   - **Description** : Une veill√©e partag√©e avec le collectif Transbordeur pour un voyage √† la rencontre des habitants d'un quartier.\n",
      "   - **Date** : Du 21/07/2025 √† 07:30 au 31/07/2025 √† 15:30\n",
      "\n",
      "Profitez de ces √©v√©nements pour d√©couvrir Marseille sous un jour nouveau !\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 5 : Recherche gratuite\n",
    "print(\"üí¨ User: Des √©v√©nements gratuits ce week-end\\n\")\n",
    "response = rag.chat(\"√©v√©nements gratuits\")\n",
    "print(f\"ü§ñ Assistant:\\n{response}\")\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Interface Interactive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b726916a98400891290cd8c278d3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>ü§ñ Assistant √âv√©nements Mistral</h2>'), Text(value='', description='Question:', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Cr√©er l'interface\n",
    "query_input = widgets.Text(\n",
    "    placeholder=\"Posez votre question...\",\n",
    "    description=\"Question:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "search_button = widgets.Button(description=\"üîç Rechercher\", button_style=\"primary\")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "\n",
    "def on_search_click(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        query = query_input.value\n",
    "\n",
    "        if query:\n",
    "            print(f\"üí¨ Recherche : {query}\\n\")\n",
    "            print(\"‚è≥ G√©n√©ration de la r√©ponse...\\n\")\n",
    "\n",
    "            response = rag.chat(query, top_k=5)\n",
    "            print(\"ü§ñ Assistant :\")\n",
    "            display(Markdown(response))\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Veuillez saisir une question\")\n",
    "\n",
    "\n",
    "search_button.on_click(on_search_click)\n",
    "\n",
    "# Afficher l'interface\n",
    "display(\n",
    "    widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(\"<h2>ü§ñ Assistant √âv√©nements Mistral</h2>\"),\n",
    "            query_input,\n",
    "            search_button,\n",
    "            output_area,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ M√©triques de Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Test : concert jazz\n",
      "   ‚Üí 2.34s\n",
      "\n",
      "‚è±Ô∏è Test : expo art\n",
      "   ‚Üí 2.54s\n",
      "\n",
      "‚è±Ô∏è Test : th√©√¢tre enfants\n",
      "   ‚Üí 2.02s\n",
      "\n",
      "\n",
      "‚ö° Performance syst√®me complet :\n",
      "  Temps moyen : 2.30 s\n",
      "  Temps min : 2.02 s\n",
      "  Temps max : 2.54 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark end-to-end\n",
    "queries = [\n",
    "    \"concert jazz\",\n",
    "    \"expo art\",\n",
    "    \"th√©√¢tre enfants\",\n",
    "]\n",
    "\n",
    "times = []\n",
    "for query in queries:\n",
    "    print(f\"‚è±Ô∏è Test : {query}\")\n",
    "    start = time.time()\n",
    "    _ = rag.chat(query)\n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "    print(f\"   ‚Üí {elapsed:.2f}s\\n\")\n",
    "\n",
    "print(\"\\n‚ö° Performance syst√®me complet :\")\n",
    "print(f\"  Temps moyen : {np.mean(times):.2f} s\")\n",
    "print(f\"  Temps min : {min(times):.2f} s\")\n",
    "print(f\"  Temps max : {max(times):.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ R√©sum√©\n",
    "\n",
    "### Points forts du syst√®me\n",
    "\n",
    "‚úÖ **Embeddings Mistral** : Vecteurs de haute qualit√© (1024 dimensions)  \n",
    "‚úÖ **LLM Mistral** : R√©ponses naturelles et contextuelles  \n",
    "‚úÖ **Recherche s√©mantique** : Pertinence √©lev√©e  \n",
    "‚úÖ **API unique** : Un seul provider pour tout le pipeline\n",
    "\n",
    "### Avantages Mistral AI\n",
    "\n",
    "- üá´üá∑ Optimis√© pour le fran√ßais\n",
    "- üöÄ R√©ponses rapides et coh√©rentes\n",
    "- üîí H√©bergement europ√©en (conformit√© RGPD)\n",
    "- üí∞ Tarification comp√©titive\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OC7---Projet-RAG-Assistant-Intelligent-Events",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
